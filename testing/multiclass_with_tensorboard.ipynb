{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97e8b0f",
   "metadata": {},
   "source": [
    "# Testing multiclass classification and using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091f30b",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8503030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7973f0b3af10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from contextlib import contextmanager\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6167f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33ed318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data-unversioned/p1ch7/\"\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2fec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b1a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = [\"airplane\", \"bird\"]\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374962dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2ebbd",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "620edea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    \"\"\"Run one epoch of training.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: Training data loader\n",
    "        optimizer: PyTorch optimizer\n",
    "        loss_fn: Loss function\n",
    "        device: Device to run on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing training metrics\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_train = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total_train += labels.shape[0]\n",
    "        correct_train += int((predicted == labels).sum())\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_loss = loss_train / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    \n",
    "    return {\n",
    "        'loss': train_loss,\n",
    "        'accuracy': train_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8537738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def create_summary_writer(model_name, hyperparams=None):\n",
    "    \"\"\"Context manager for creating and managing a TensorBoard SummaryWriter.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model for the log directory\n",
    "        hyperparams (dict, optional): Hyperparameters to log\n",
    "        \n",
    "    Yields:\n",
    "        SummaryWriter: TensorBoard writer\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_architecture = hyperparams.get('model_architecture', '') if hyperparams else ''\n",
    "    log_dir = f\"runs/{model_name}_{model_architecture}_{timestamp}\"\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    \n",
    "    print(f\"TensorBoard logs will be saved to {log_dir}\")\n",
    "    \n",
    "    if hyperparams:\n",
    "        # Log hyperparameters as text\n",
    "        param_str = \"\\n\".join([f\"{k}: {v}\" for k, v in hyperparams.items()])\n",
    "        writer.add_text('Hyperparameters', param_str)\n",
    "    \n",
    "    try:\n",
    "        yield writer\n",
    "    finally:\n",
    "        writer.close()\n",
    "        print(f\"TensorBoard writer closed for {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d755fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, loss_fn, device, class_names=None):\n",
    "    \"\"\"Evaluate the model on validation data.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        val_loader: Validation data loader\n",
    "        loss_fn: Loss function\n",
    "        device: Device to run on\n",
    "        class_names (list, optional): List of class names\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing validation metrics and predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total_val += labels.shape[0]\n",
    "            correct_val += int((predicted == labels).sum())\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'f1': val_f1,\n",
    "        'predictions': all_preds,\n",
    "        'true_labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d75707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(writer, train_metrics, val_metrics, optimizer, epoch):\n",
    "    \"\"\"Log metrics to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        train_metrics (dict): Training metrics\n",
    "        val_metrics (dict): Validation metrics\n",
    "        optimizer: PyTorch optimizer\n",
    "        epoch (int): Current epoch\n",
    "    \"\"\"\n",
    "    # Log scalar metrics\n",
    "    writer.add_scalar('Loss/train', train_metrics['loss'], epoch)\n",
    "    writer.add_scalar('Loss/validation', val_metrics['loss'], epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_metrics['accuracy'], epoch)\n",
    "    writer.add_scalar('Accuracy/validation', val_metrics['accuracy'], epoch)\n",
    "    writer.add_scalar('F1/validation', val_metrics['f1'], epoch)\n",
    "    \n",
    "    # Log learning rate\n",
    "    writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0009108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_info(writer, model, epoch, train_loader, device):\n",
    "    \"\"\"Log model parameters and gradients to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        model: PyTorch model\n",
    "        epoch (int): Current epoch\n",
    "        train_loader: Training data loader\n",
    "        device: Device to run on\n",
    "    \"\"\"\n",
    "    # Log model graph (only once)\n",
    "    if epoch == 1:\n",
    "        example_images, _ = next(iter(train_loader))\n",
    "        try:\n",
    "            writer.add_graph(model, example_images.to(device))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to add model graph to TensorBoard: {e}\")\n",
    "    \n",
    "    # Log histograms of model parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(f'Parameters/{name}', param, epoch)\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(f'Gradients/{name}', param.grad, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2578a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_predictions(writer, model, val_loader, device, class_names, epoch, num_images=10):\n",
    "    \"\"\"Log prediction visualizations to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        model: PyTorch model\n",
    "        val_loader: Validation data loader\n",
    "        device: Device to run on\n",
    "        class_names (list): List of class names\n",
    "        epoch (int): Current epoch\n",
    "        num_images (int): Number of images to visualize\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            for j in range(imgs.size()[0]):\n",
    "                if images_so_far >= num_images:\n",
    "                    break\n",
    "                \n",
    "                ax = plt.subplot(2, num_images//2, images_so_far + 1)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'pred: {class_names[preds[j]]}\\ntrue: {class_names[labels[j]]}',\n",
    "                           color=(\"green\" if preds[j]==labels[j] else \"red\"))\n",
    "                \n",
    "                # Denormalize and convert to numpy for matplotlib\n",
    "                img = imgs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "                mean = np.array([0.4915, 0.4823, 0.4468])\n",
    "                std = np.array([0.2470, 0.2435, 0.2616])\n",
    "                img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                \n",
    "                plt.imshow(img)\n",
    "                images_so_far += 1\n",
    "                if images_so_far >= num_images:\n",
    "                    break\n",
    "    \n",
    "    writer.add_figure(f'Predictions/Epoch_{epoch}', fig, epoch)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20991202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_embeddings(writer, model, val_loader, device, class_names, n_epochs):\n",
    "    \"\"\"Log embeddings to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        model: PyTorch model\n",
    "        val_loader: Validation data loader\n",
    "        device: Device to run on\n",
    "        class_names (list): List of class names\n",
    "        n_epochs (int): Total number of epochs\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # Get features from the last layer before classification\n",
    "    def hook_fn(module, input, output):\n",
    "        features.append(input[0].cpu().numpy())\n",
    "    \n",
    "    # Register hook to the second-to-last layer\n",
    "    try:\n",
    "        handle = model.fc1.register_forward_hook(hook_fn)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                model(imgs)\n",
    "                labels_list.extend(labels.numpy())\n",
    "        \n",
    "        handle.remove()\n",
    "        \n",
    "        # Concatenate all features\n",
    "        features = np.concatenate(features)\n",
    "        \n",
    "        # Select a subset of data for visualization (max 10000 points)\n",
    "        max_samples = min(10000, len(features))\n",
    "        indices = np.random.choice(len(features), max_samples, replace=False)\n",
    "        \n",
    "        # Log embeddings\n",
    "        writer.add_embedding(\n",
    "            features[indices],\n",
    "            metadata=[class_names[l] for l in np.array(labels_list)[indices]],\n",
    "            label_img=None,\n",
    "            global_step=n_epochs\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to log embeddings to TensorBoard: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08739c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to terminate training when validation loss doesn't improve.\n",
    "    \n",
    "    Args:\n",
    "        patience (int): How many epochs to wait after last improvement.\n",
    "        min_delta (float): Minimum change to qualify as an improvement.\n",
    "        mode (str): 'min' for monitoring metrics that decrease (like loss),\n",
    "                    'max' for metrics that increase (like accuracy).\n",
    "        verbose (bool): If True, prints a message for each improvement.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.0, mode='min', verbose=False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "        # Set the direction based on mode\n",
    "        self.monitor_op = np.less if mode == 'min' else np.greater\n",
    "        self.min_delta = min_delta if mode == 'min' else -min_delta\n",
    "        \n",
    "    def __call__(self, epoch, current_score, model=None, path=None):\n",
    "        \"\"\"Check if training should be stopped.\n",
    "        \n",
    "        Args:\n",
    "            epoch (int): Current epoch number\n",
    "            current_score (float): Current validation metric to monitor\n",
    "            model (torch.nn.Module, optional): Model to save if score improves\n",
    "            path (str, optional): Path to save the model\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if training should stop, False otherwise\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            # First epoch\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.save_checkpoint(current_score, model, path)\n",
    "        elif self.monitor_op(current_score - self.min_delta, self.best_score):\n",
    "            # Score improved\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(current_score, model, path)\n",
    "        else:\n",
    "            # Score did not improve\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                \n",
    "        return self.early_stop\n",
    "    \n",
    "    def save_checkpoint(self, score, model, path):\n",
    "        \"\"\"Save model when validation score improves.\"\"\"\n",
    "        if self.verbose:\n",
    "            improved = 'improved' if self.best_score == score else 'did not improve'\n",
    "            metric_name = 'loss' if self.mode == 'min' else 'score'\n",
    "            print(f'Validation {metric_name} {improved} ({self.best_score:.6f} --> {score:.6f})')\n",
    "        \n",
    "        if model is not None and path is not None:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            if self.verbose:\n",
    "                print(f'Model saved to {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ef8ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader, \n",
    "                  epoch_trainer, device, class_names, model_name=\"model\", \n",
    "                  early_stopping_params=None):\n",
    "    \"\"\"Main training loop with TensorBoard logging and early stopping.\n",
    "    \n",
    "    Args:\n",
    "        n_epochs (int): Maximum number of epochs\n",
    "        optimizer: PyTorch optimizer\n",
    "        model: PyTorch model\n",
    "        loss_fn: Loss function\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        device: Device to run on\n",
    "        class_names (list): List of class names\n",
    "        model_name (str): Name for the model in logs\n",
    "        early_stopping_params (dict, optional): Parameters for early stopping\n",
    "            {\n",
    "                'patience': int,\n",
    "                'min_delta': float,\n",
    "                'metric': str ('loss', 'accuracy', or 'f1'),\n",
    "                'mode': str ('min' or 'max')\n",
    "            }\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing best metrics\n",
    "    \"\"\"\n",
    "    print(f\"Training on device {device}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device=device)\n",
    "    \n",
    "    # Setup early stopping if parameters are provided\n",
    "    early_stopping = None\n",
    "    if early_stopping_params:\n",
    "        metric = early_stopping_params.get('metric', 'f1')\n",
    "        mode = early_stopping_params.get('mode', 'min' if metric == 'loss' else 'max')\n",
    "        patience = early_stopping_params.get('patience', 10)\n",
    "        min_delta = early_stopping_params.get('min_delta', 0.0)\n",
    "        verbose = early_stopping_params.get('verbose', False)\n",
    "        \n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=patience,\n",
    "            min_delta=min_delta,\n",
    "            mode=mode,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        print(f\"Early stopping enabled: monitoring {metric}, mode={mode}, patience={patience}\")\n",
    "    \n",
    "    # Create hyperparameters dict for logging\n",
    "    hyperparams = {\n",
    "        'batch_size': train_loader.batch_size,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "        'weight_decay': optimizer.param_groups[0].get('weight_decay', 0),\n",
    "        'epochs': n_epochs,\n",
    "        'optimizer': optimizer.__class__.__name__,\n",
    "        'model_architecture': model.__class__.__name__,\n",
    "    }\n",
    "    \n",
    "    if early_stopping_params:\n",
    "        hyperparams.update({\n",
    "            'early_stopping_metric': early_stopping_params.get('metric', 'loss'),\n",
    "            'early_stopping_patience': early_stopping_params.get('patience', 10),\n",
    "            'early_stopping_min_delta': early_stopping_params.get('min_delta', 0.0),\n",
    "        })\n",
    "    \n",
    "    # Create TensorBoard writer using context manager\n",
    "    with create_summary_writer(model_name, hyperparams) as writer:\n",
    "        best_val_f1 = 0.0\n",
    "        best_metrics = {}\n",
    "        \n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            # Train for one epoch\n",
    "            train_metrics = epoch_trainer(model, train_loader, optimizer, loss_fn, device)\n",
    "            \n",
    "            # Evaluate the model\n",
    "            val_metrics = evaluate_model(model, val_loader, loss_fn, device, class_names)\n",
    "            \n",
    "            # Log metrics to TensorBoard\n",
    "            log_metrics(writer, train_metrics, val_metrics, optimizer, epoch)\n",
    "            \n",
    "            # Log model information periodically\n",
    "            if epoch % 10 == 0 or epoch == 1:\n",
    "                log_model_info(writer, model, epoch, train_loader, device)\n",
    "                log_predictions(writer, model, val_loader, device, class_names, epoch)\n",
    "            \n",
    "            # Print metrics periodically\n",
    "            if epoch == 1 or epoch % 5 == 0:\n",
    "                print(f\"{datetime.datetime.now()} Epoch {epoch}\")\n",
    "                print(f\"  Training:   Loss: {train_metrics['loss']:.4f}, Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "                print(f\"  Validation: Loss: {val_metrics['loss']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
    "            \n",
    "            # Save best model based on F1 score\n",
    "            if val_metrics['f1'] > best_val_f1:\n",
    "                best_val_f1 = val_metrics['f1']\n",
    "                best_metrics = val_metrics.copy()\n",
    "                torch.save(model.state_dict(), f\"runs/{model_name}_best_model.pth\")\n",
    "            \n",
    "            # Check early stopping condition\n",
    "            if early_stopping:\n",
    "                # Get the metric to monitor\n",
    "                metric_name = early_stopping_params.get('metric', 'loss')\n",
    "                current_metric = val_metrics[metric_name]\n",
    "                \n",
    "                # Call early stopping with current metric\n",
    "                model_path = f\"runs/{model_name}_early_stopping.pth\"\n",
    "                if early_stopping(epoch, current_metric, model, model_path):\n",
    "                    print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                    print(f\"Best {metric_name} was at epoch {early_stopping.best_epoch}\")\n",
    "                    break\n",
    "        \n",
    "        # Log embeddings after training is complete\n",
    "        log_embeddings(writer, model, val_loader, device, class_names, epoch)\n",
    "        \n",
    "        # Log final hyperparameters with metrics\n",
    "        final_metrics = {\n",
    "            'hparam/val_accuracy': val_metrics['accuracy'],\n",
    "            'hparam/val_f1': val_metrics['f1'],\n",
    "            'hparam/val_loss': val_metrics['loss'],\n",
    "            'hparam/epochs_trained': epoch\n",
    "        }\n",
    "        writer.add_hparams(hyperparams, final_metrics)\n",
    "    \n",
    "    # Set the model to evaluation mode after training\n",
    "    model.eval()\n",
    "    print(f\"Training complete. Best validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    # If early stopping was used, report the best epoch\n",
    "    if early_stopping:\n",
    "        print(f\"Best {early_stopping_params.get('metric', 'loss')} was at epoch {early_stopping.best_epoch}\")\n",
    "    \n",
    "    return best_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7312eb",
   "metadata": {},
   "source": [
    "## Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dbd4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=512, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=512, shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463554aa",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f8763e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cifar2_model\"\n",
    "n_epochs = 200\n",
    "early_stopping_params = {\n",
    "    'metric': 'f1',      # Monitor F1 score\n",
    "    'mode': 'max',       # We want to maximize F1\n",
    "    'patience': 5,       # Wait for 5 epochs before stopping\n",
    "    'min_delta': 0.001   # Minimum change to qualify as improvement\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14c6c8",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d5f3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f394b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_Net_20250406-235253\n",
      "2025-04-06 23:52:55.742554 Epoch 1\n",
      "  Training:   Loss: 0.5445, Accuracy: 0.7376\n",
      "  Validation: Loss: 0.4538, Accuracy: 0.7955, F1: 0.7955\n",
      "2025-04-06 23:52:56.409518 Epoch 5\n",
      "  Training:   Loss: 0.3390, Accuracy: 0.8511\n",
      "  Validation: Loss: 0.3317, Accuracy: 0.8510, F1: 0.8510\n",
      "2025-04-06 23:52:57.867946 Epoch 10\n",
      "  Training:   Loss: 0.2932, Accuracy: 0.8757\n",
      "  Validation: Loss: 0.3069, Accuracy: 0.8655, F1: 0.8654\n",
      "2025-04-06 23:52:59.253874 Epoch 15\n",
      "  Training:   Loss: 0.2647, Accuracy: 0.8875\n",
      "  Validation: Loss: 0.2920, Accuracy: 0.8725, F1: 0.8725\n",
      "2025-04-06 23:53:01.021586 Epoch 20\n",
      "  Training:   Loss: 0.2429, Accuracy: 0.8975\n",
      "  Validation: Loss: 0.2858, Accuracy: 0.8785, F1: 0.8785\n",
      "2025-04-06 23:53:02.399546 Epoch 25\n",
      "  Training:   Loss: 0.2228, Accuracy: 0.9080\n",
      "  Validation: Loss: 0.2832, Accuracy: 0.8840, F1: 0.8840\n",
      "Early stopping triggered at epoch 29\n",
      "Best f1 was at epoch 24\n",
      "TensorBoard writer closed for runs/cifar2_model_Net_20250406-235253\n",
      "Training complete. Best validation F1: 0.8850\n",
      "Best f1 was at epoch 24\n"
     ]
    }
   ],
   "source": [
    "# We transfer the model (all its parameters) to the device.\n",
    "model = Net().to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"baseline\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d023541",
   "metadata": {},
   "source": [
    "### Augmenting width or channels in convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a594fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWidth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5383628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetWidth_20250406-235304\n",
      "2025-04-06 23:53:05.330123 Epoch 1\n",
      "  Training:   Loss: 0.4999, Accuracy: 0.7629\n",
      "  Validation: Loss: 0.4134, Accuracy: 0.8140, F1: 0.8138\n",
      "2025-04-06 23:53:06.609069 Epoch 5\n",
      "  Training:   Loss: 0.3268, Accuracy: 0.8619\n",
      "  Validation: Loss: 0.3215, Accuracy: 0.8570, F1: 0.8570\n",
      "2025-04-06 23:53:08.614469 Epoch 10\n",
      "  Training:   Loss: 0.2721, Accuracy: 0.8852\n",
      "  Validation: Loss: 0.2835, Accuracy: 0.8805, F1: 0.8805\n",
      "2025-04-06 23:53:10.224383 Epoch 15\n",
      "  Training:   Loss: 0.2248, Accuracy: 0.9042\n",
      "  Validation: Loss: 0.2767, Accuracy: 0.8920, F1: 0.8919\n",
      "2025-04-06 23:53:12.447016 Epoch 20\n",
      "  Training:   Loss: 0.1899, Accuracy: 0.9216\n",
      "  Validation: Loss: 0.2721, Accuracy: 0.8945, F1: 0.8944\n",
      "Early stopping triggered at epoch 24\n",
      "Best f1 was at epoch 19\n",
      "TensorBoard writer closed for runs/cifar2_model_NetWidth_20250406-235304\n",
      "Training complete. Best validation F1: 0.8954\n",
      "Best f1 was at epoch 19\n"
     ]
    }
   ],
   "source": [
    "model = NetWidth(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"width\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d43c0",
   "metadata": {},
   "source": [
    "### $L_2$-regularizarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96e3e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_epoch_trainer(model, train_loader, optimizer, loss_fn, device):\n",
    "    \"\"\"Run one epoch of training.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: Training data loader\n",
    "        optimizer: PyTorch optimizer\n",
    "        loss_fn: Loss function\n",
    "        device: Device to run on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing training metrics\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_train = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        l2_lambda = 0.001\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total_train += labels.shape[0]\n",
    "        correct_train += int((predicted == labels).sum())\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_loss = loss_train / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    \n",
    "    return {\n",
    "        'loss': train_loss,\n",
    "        'accuracy': train_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4392a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_Net_20250406-235315\n",
      "2025-04-06 23:53:16.550360 Epoch 1\n",
      "  Training:   Loss: 0.5645, Accuracy: 0.7459\n",
      "  Validation: Loss: 0.4441, Accuracy: 0.7975, F1: 0.7975\n",
      "2025-04-06 23:53:17.798328 Epoch 5\n",
      "  Training:   Loss: 0.3610, Accuracy: 0.8558\n",
      "  Validation: Loss: 0.3319, Accuracy: 0.8500, F1: 0.8500\n",
      "2025-04-06 23:53:19.778436 Epoch 10\n",
      "  Training:   Loss: 0.3217, Accuracy: 0.8740\n",
      "  Validation: Loss: 0.3061, Accuracy: 0.8680, F1: 0.8679\n",
      "2025-04-06 23:53:21.329942 Epoch 15\n",
      "  Training:   Loss: 0.3025, Accuracy: 0.8821\n",
      "  Validation: Loss: 0.3075, Accuracy: 0.8660, F1: 0.8657\n",
      "2025-04-06 23:53:23.281261 Epoch 20\n",
      "  Training:   Loss: 0.2886, Accuracy: 0.8864\n",
      "  Validation: Loss: 0.2865, Accuracy: 0.8765, F1: 0.8765\n",
      "2025-04-06 23:53:24.827088 Epoch 25\n",
      "  Training:   Loss: 0.2721, Accuracy: 0.8963\n",
      "  Validation: Loss: 0.2813, Accuracy: 0.8825, F1: 0.8825\n",
      "2025-04-06 23:53:27.025365 Epoch 30\n",
      "  Training:   Loss: 0.2580, Accuracy: 0.9048\n",
      "  Validation: Loss: 0.2757, Accuracy: 0.8835, F1: 0.8835\n",
      "2025-04-06 23:53:28.300688 Epoch 35\n",
      "  Training:   Loss: 0.2473, Accuracy: 0.9107\n",
      "  Validation: Loss: 0.2722, Accuracy: 0.8860, F1: 0.8860\n",
      "2025-04-06 23:53:30.183215 Epoch 40\n",
      "  Training:   Loss: 0.2369, Accuracy: 0.9170\n",
      "  Validation: Loss: 0.2690, Accuracy: 0.8895, F1: 0.8895\n",
      "2025-04-06 23:53:31.675360 Epoch 45\n",
      "  Training:   Loss: 0.2270, Accuracy: 0.9243\n",
      "  Validation: Loss: 0.2663, Accuracy: 0.8910, F1: 0.8910\n",
      "2025-04-06 23:53:33.599697 Epoch 50\n",
      "  Training:   Loss: 0.2174, Accuracy: 0.9317\n",
      "  Validation: Loss: 0.2646, Accuracy: 0.8935, F1: 0.8935\n",
      "2025-04-06 23:53:35.139965 Epoch 55\n",
      "  Training:   Loss: 0.2084, Accuracy: 0.9369\n",
      "  Validation: Loss: 0.2637, Accuracy: 0.8930, F1: 0.8930\n",
      "Early stopping triggered at epoch 58\n",
      "Best f1 was at epoch 53\n",
      "TensorBoard writer closed for runs/cifar2_model_Net_20250406-235315\n",
      "Training complete. Best validation F1: 0.8945\n",
      "Best f1 was at epoch 53\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"l2 reg\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=l2_epoch_trainer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26c602",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de29f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33e161cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetDropout_20250406-235337\n",
      "2025-04-06 23:53:37.913475 Epoch 1\n",
      "  Training:   Loss: 0.5313, Accuracy: 0.7493\n",
      "  Validation: Loss: 0.4241, Accuracy: 0.8055, F1: 0.8054\n",
      "2025-04-06 23:53:39.203415 Epoch 5\n",
      "  Training:   Loss: 0.3770, Accuracy: 0.8361\n",
      "  Validation: Loss: 0.3384, Accuracy: 0.8445, F1: 0.8445\n",
      "2025-04-06 23:53:41.463739 Epoch 10\n",
      "  Training:   Loss: 0.3386, Accuracy: 0.8544\n",
      "  Validation: Loss: 0.3156, Accuracy: 0.8610, F1: 0.8610\n",
      "2025-04-06 23:53:43.070221 Epoch 15\n",
      "  Training:   Loss: 0.3152, Accuracy: 0.8664\n",
      "  Validation: Loss: 0.2998, Accuracy: 0.8730, F1: 0.8730\n",
      "2025-04-06 23:53:45.088906 Epoch 20\n",
      "  Training:   Loss: 0.2863, Accuracy: 0.8774\n",
      "  Validation: Loss: 0.2860, Accuracy: 0.8820, F1: 0.8820\n",
      "2025-04-06 23:53:46.687729 Epoch 25\n",
      "  Training:   Loss: 0.2678, Accuracy: 0.8854\n",
      "  Validation: Loss: 0.2752, Accuracy: 0.8875, F1: 0.8875\n",
      "2025-04-06 23:53:48.698334 Epoch 30\n",
      "  Training:   Loss: 0.2471, Accuracy: 0.8979\n",
      "  Validation: Loss: 0.2665, Accuracy: 0.8890, F1: 0.8890\n",
      "2025-04-06 23:53:50.298319 Epoch 35\n",
      "  Training:   Loss: 0.2317, Accuracy: 0.9045\n",
      "  Validation: Loss: 0.2670, Accuracy: 0.8910, F1: 0.8909\n",
      "2025-04-06 23:53:52.273184 Epoch 40\n",
      "  Training:   Loss: 0.2154, Accuracy: 0.9104\n",
      "  Validation: Loss: 0.2580, Accuracy: 0.8980, F1: 0.8980\n",
      "2025-04-06 23:53:53.860166 Epoch 45\n",
      "  Training:   Loss: 0.2053, Accuracy: 0.9165\n",
      "  Validation: Loss: 0.2557, Accuracy: 0.9020, F1: 0.9020\n",
      "2025-04-06 23:53:56.002939 Epoch 50\n",
      "  Training:   Loss: 0.1959, Accuracy: 0.9196\n",
      "  Validation: Loss: 0.2595, Accuracy: 0.8980, F1: 0.8980\n",
      "Early stopping triggered at epoch 50\n",
      "Best f1 was at epoch 45\n",
      "TensorBoard writer closed for runs/cifar2_model_NetDropout_20250406-235337\n",
      "Training complete. Best validation F1: 0.9020\n",
      "Best f1 was at epoch 45\n"
     ]
    }
   ],
   "source": [
    "model = NetDropout(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"dropout\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9a003",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e234fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14d9237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetBatchNorm_20250406-235358\n",
      "2025-04-06 23:53:58.953959 Epoch 1\n",
      "  Training:   Loss: 0.4592, Accuracy: 0.7871\n",
      "  Validation: Loss: 0.3844, Accuracy: 0.8295, F1: 0.8288\n",
      "2025-04-06 23:54:00.340383 Epoch 5\n",
      "  Training:   Loss: 0.2937, Accuracy: 0.8762\n",
      "  Validation: Loss: 0.3025, Accuracy: 0.8665, F1: 0.8665\n",
      "2025-04-06 23:54:02.537246 Epoch 10\n",
      "  Training:   Loss: 0.2285, Accuracy: 0.9058\n",
      "  Validation: Loss: 0.2758, Accuracy: 0.8805, F1: 0.8804\n",
      "2025-04-06 23:54:04.261773 Epoch 15\n",
      "  Training:   Loss: 0.1716, Accuracy: 0.9318\n",
      "  Validation: Loss: 0.2722, Accuracy: 0.8890, F1: 0.8890\n",
      "2025-04-06 23:54:06.492120 Epoch 20\n",
      "  Training:   Loss: 0.1210, Accuracy: 0.9591\n",
      "  Validation: Loss: 0.2766, Accuracy: 0.8985, F1: 0.8984\n",
      "2025-04-06 23:54:07.914866 Epoch 25\n",
      "  Training:   Loss: 0.0919, Accuracy: 0.9715\n",
      "  Validation: Loss: 0.2922, Accuracy: 0.8975, F1: 0.8974\n",
      "Early stopping triggered at epoch 28\n",
      "Best f1 was at epoch 23\n",
      "TensorBoard writer closed for runs/cifar2_model_NetBatchNorm_20250406-235358\n",
      "Training complete. Best validation F1: 0.9030\n",
      "Best f1 was at epoch 23\n"
     ]
    }
   ],
   "source": [
    "model = NetBatchNorm(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"batch_norm\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce573c8",
   "metadata": {},
   "source": [
    "### Augmenting depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dd2629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDepth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25858d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetDepth_20250406-235410\n",
      "2025-04-06 23:54:11.008018 Epoch 1\n",
      "  Training:   Loss: 0.5941, Accuracy: 0.6856\n",
      "  Validation: Loss: 0.4694, Accuracy: 0.7990, F1: 0.7990\n",
      "2025-04-06 23:54:11.775577 Epoch 5\n",
      "  Training:   Loss: 0.3409, Accuracy: 0.8565\n",
      "  Validation: Loss: 0.3392, Accuracy: 0.8485, F1: 0.8485\n",
      "2025-04-06 23:54:13.857933 Epoch 10\n",
      "  Training:   Loss: 0.2976, Accuracy: 0.8749\n",
      "  Validation: Loss: 0.3075, Accuracy: 0.8625, F1: 0.8625\n",
      "2025-04-06 23:54:15.051893 Epoch 15\n",
      "  Training:   Loss: 0.2707, Accuracy: 0.8886\n",
      "  Validation: Loss: 0.2889, Accuracy: 0.8770, F1: 0.8769\n",
      "2025-04-06 23:54:16.396431 Epoch 20\n",
      "  Training:   Loss: 0.2429, Accuracy: 0.9008\n",
      "  Validation: Loss: 0.2706, Accuracy: 0.8885, F1: 0.8885\n",
      "2025-04-06 23:54:17.980830 Epoch 25\n",
      "  Training:   Loss: 0.2174, Accuracy: 0.9124\n",
      "  Validation: Loss: 0.2635, Accuracy: 0.8980, F1: 0.8980\n",
      "2025-04-06 23:54:19.973770 Epoch 30\n",
      "  Training:   Loss: 0.1914, Accuracy: 0.9229\n",
      "  Validation: Loss: 0.2604, Accuracy: 0.8995, F1: 0.8995\n",
      "2025-04-06 23:54:21.547340 Epoch 35\n",
      "  Training:   Loss: 0.1708, Accuracy: 0.9324\n",
      "  Validation: Loss: 0.2574, Accuracy: 0.8995, F1: 0.8995\n",
      "Early stopping triggered at epoch 37\n",
      "Best f1 was at epoch 32\n",
      "TensorBoard writer closed for runs/cifar2_model_NetDepth_20250406-235410\n",
      "Training complete. Best validation F1: 0.9015\n",
      "Best f1 was at epoch 32\n"
     ]
    }
   ],
   "source": [
    "model = NetDepth(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"depth\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847bbab",
   "metadata": {},
   "source": [
    "### Residual connections (ResNets) or skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b723ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b20e4acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetRes_20250406-235422\n",
      "2025-04-06 23:54:23.734832 Epoch 1\n",
      "  Training:   Loss: 0.5706, Accuracy: 0.7191\n",
      "  Validation: Loss: 0.4548, Accuracy: 0.8010, F1: 0.8006\n",
      "2025-04-06 23:54:25.006007 Epoch 5\n",
      "  Training:   Loss: 0.3265, Accuracy: 0.8604\n",
      "  Validation: Loss: 0.3253, Accuracy: 0.8525, F1: 0.8524\n",
      "2025-04-06 23:54:27.006950 Epoch 10\n",
      "  Training:   Loss: 0.2873, Accuracy: 0.8796\n",
      "  Validation: Loss: 0.2983, Accuracy: 0.8680, F1: 0.8678\n",
      "2025-04-06 23:54:28.583271 Epoch 15\n",
      "  Training:   Loss: 0.2584, Accuracy: 0.8922\n",
      "  Validation: Loss: 0.2864, Accuracy: 0.8770, F1: 0.8767\n",
      "2025-04-06 23:54:30.628119 Epoch 20\n",
      "  Training:   Loss: 0.2338, Accuracy: 0.9034\n",
      "  Validation: Loss: 0.2702, Accuracy: 0.8900, F1: 0.8898\n",
      "2025-04-06 23:54:32.217374 Epoch 25\n",
      "  Training:   Loss: 0.2133, Accuracy: 0.9130\n",
      "  Validation: Loss: 0.2570, Accuracy: 0.8970, F1: 0.8969\n",
      "2025-04-06 23:54:34.297488 Epoch 30\n",
      "  Training:   Loss: 0.1968, Accuracy: 0.9198\n",
      "  Validation: Loss: 0.2548, Accuracy: 0.9015, F1: 0.9014\n",
      "2025-04-06 23:54:35.942523 Epoch 35\n",
      "  Training:   Loss: 0.1820, Accuracy: 0.9275\n",
      "  Validation: Loss: 0.2402, Accuracy: 0.9055, F1: 0.9055\n",
      "2025-04-06 23:54:38.177624 Epoch 40\n",
      "  Training:   Loss: 0.1638, Accuracy: 0.9337\n",
      "  Validation: Loss: 0.2473, Accuracy: 0.9050, F1: 0.9049\n",
      "2025-04-06 23:54:39.756086 Epoch 45\n",
      "  Training:   Loss: 0.1487, Accuracy: 0.9415\n",
      "  Validation: Loss: 0.2450, Accuracy: 0.9030, F1: 0.9030\n",
      "Early stopping triggered at epoch 47\n",
      "Best f1 was at epoch 42\n",
      "TensorBoard writer closed for runs/cifar2_model_NetRes_20250406-235422\n",
      "Training complete. Best validation F1: 0.9060\n",
      "Best f1 was at epoch 42\n"
     ]
    }
   ],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"res\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b99e923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            n_chans, n_chans, kernel_size=3, padding=1, bias=False\n",
    "        )  # <1>\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity=\"relu\")  # <2>\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d02e5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(*(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede00ff0",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "085c2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(model_class, model_path, test_loader, device, class_names):\n",
    "    \"\"\"\n",
    "    Perform final evaluation of the model on the test set.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model weights\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Device to run on\n",
    "        class_names: List of class names\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing test metrics\n",
    "    \"\"\"\n",
    "    # Initialize model and load weights\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    test_metrics = evaluate_model(model, test_loader, loss_fn, device, class_names)\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    print(\"\\n===== FINAL MODEL EVALUATION =====\")\n",
    "    print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    y_true = np.array(test_metrics['true_labels'])\n",
    "    y_pred = np.array(test_metrics['predictions'])\n",
    "    \n",
    "    # Precision, recall per class\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    print(\"\\nPer-class performance:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:10s}: Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1[i]:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Add text annotations to confusion matrix\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d29a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL MODEL EVALUATION =====\n",
      "Test Accuracy: 0.9060\n",
      "Test F1 Score: 0.9060\n",
      "\n",
      "Per-class performance:\n",
      "airplane  : Precision: 0.9194, Recall: 0.8900, F1: 0.9045\n",
      "bird      : Precision: 0.8934, Recall: 0.9220, F1: 0.9075\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA40AAAMpCAYAAACg2dbBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABuF0lEQVR4nO3deZxO9fvH8fe5Z2WYGWRmTBhbWUK2YsqaiSxFtJAyREomW4iyL+mrRERahESiL4osWYpkyDa+QkK2YoZoZmyz378/NPfP3Tg1cxvOzO31nMd5PLrP+Zzzuc79h+aa6zqfY9jtdrsAAAAAALgGm9UBAAAAAADyLpJGAAAAAIApkkYAAAAAgCmSRgAAAACAKZJGAAAAAIApkkYAAAAAgCmSRgAAAACAKZJGAAAAAIApkkYAAAAAgCmSRgBArjh48KCaNWumgIAAGYahpUuX5ur1jx49KsMwNHv27Fy9bn7WuHFjNW7c2OowAABujqQRANzI4cOH9fzzz6tcuXLy9fWVv7+/7r//fr3zzju6fPnyDZ07MjJSe/bs0bhx4zR37lzVqVPnhs53M3Xp0kWGYcjf3/+a3+PBgwdlGIYMw9Bbb72V4+ufPHlSI0eOVExMTC5ECwBA7vK0OgAAQO74+uuv9fjjj8vHx0edO3dW1apVlZKSok2bNmngwIHau3evPvjggxsy9+XLlxUdHa3XXntNUVFRN2SOsLAwXb58WV5eXjfk+v/G09NTly5d0rJly/TEE084HZs3b558fX2VlJTk0rVPnjypUaNGqUyZMqpRo0a2z/vmm29cmg8AgJwgaQQAN3DkyBF16NBBYWFhWr9+vUqUKOE41qtXLx06dEhff/31DZv/zJkzkqTAwMAbNodhGPL19b1h1/83Pj4+uv/++/XZZ59lSRrnz5+vVq1a6b///e9NieXSpUsqWLCgvL29b8p8AIBbG+2pAOAGJkyYoAsXLmjmzJlOCWOmChUqqE+fPo7PaWlpGjNmjMqXLy8fHx+VKVNGr776qpKTk53OK1OmjFq3bq1Nmzbp3nvvla+vr8qVK6dPPvnEMWbkyJEKCwuTJA0cOFCGYahMmTKSrrR1Zv731UaOHCnDMJz2rVmzRvXr11dgYKAKFSqkihUr6tVXX3UcN3umcf369WrQoIH8/PwUGBioNm3aaP/+/dec79ChQ+rSpYsCAwMVEBCgrl276tKlS+Zf7N889dRTWrlypeLj4x37tm3bpoMHD+qpp57KMv7cuXMaMGCAqlWrpkKFCsnf318tWrTQ7t27HWO+++473XPPPZKkrl27OtpcM++zcePGqlq1qnbs2KGGDRuqYMGCju/l7880RkZGytfXN8v9N2/eXEWKFNHJkyezfa8AAGQiaQQAN7Bs2TKVK1dO9913X7bGd+/eXcOHD1etWrU0adIkNWrUSOPHj1eHDh2yjD106JAee+wxPfjgg5o4caKKFCmiLl26aO/evZKkdu3aadKkSZKkjh07au7cuZo8eXKO4t+7d69at26t5ORkjR49WhMnTtQjjzyiH3744R/PW7t2rZo3b67Tp09r5MiR6t+/vzZv3qz7779fR48ezTL+iSee0Pnz5zV+/Hg98cQTmj17tkaNGpXtONu1ayfDMLR48WLHvvnz56tSpUqqVatWlvG//vqrli5dqtatW+vtt9/WwIEDtWfPHjVq1MiRwFWuXFmjR4+WJPXo0UNz587V3Llz1bBhQ8d1zp49qxYtWqhGjRqaPHmymjRpcs343nnnHRUvXlyRkZFKT0+XJL3//vv65ptvNHXqVIWGhmb7XgEAcLADAPK1hIQEuyR7mzZtsjU+JibGLsnevXt3p/0DBgywS7KvX7/esS8sLMwuyb5x40bHvtOnT9t9fHzsL7/8smPfkSNH7JLsb775ptM1IyMj7WFhYVliGDFihP3q/wVNmjTJLsl+5swZ07gz55g1a5ZjX40aNexBQUH2s2fPOvbt3r3bbrPZ7J07d84y37PPPut0zUcffdRerFgx0zmvvg8/Pz+73W63P/bYY/amTZva7Xa7PT093R4SEmIfNWrUNb+DpKQke3p6epb78PHxsY8ePdqxb9u2bVnuLVOjRo3skuwzZsy45rFGjRo57Vu9erVdkn3s2LH2X3/91V6oUCF727Zt//UeAQAwQ6URAPK5xMRESVLhwoWzNX7FihWSpP79+zvtf/nllyUpy7OPVapUUYMGDRyfixcvrooVK+rXX391Oea/y3wW8ssvv1RGRka2zjl16pRiYmLUpUsXFS1a1LG/evXqevDBBx33ebUXXnjB6XODBg109uxZx3eYHU899ZS+++47xcbGav369YqNjb1ma6p05TlIm+3K/2rT09N19uxZR+vtzp07sz2nj4+Punbtmq2xzZo10/PPP6/Ro0erXbt28vX11fvvv5/tuQAA+DuSRgDI5/z9/SVJ58+fz9b4Y8eOyWazqUKFCk77Q0JCFBgYqGPHjjntL126dJZrFClSRH/++aeLEWf15JNP6v7771f37t0VHBysDh06aOHChf+YQGbGWbFixSzHKleurD/++EMXL1502v/3eylSpIgk5eheWrZsqcKFC+vzzz/XvHnzdM8992T5LjNlZGRo0qRJuuOOO+Tj46PbbrtNxYsX1//+9z8lJCRke87bb789R4vevPXWWypatKhiYmI0ZcoUBQUFZftcAAD+jqQRAPI5f39/hYaG6qeffsrReX9fiMaMh4fHNffb7XaX58h83i5TgQIFtHHjRq1du1bPPPOM/ve//+nJJ5/Ugw8+mGXs9biee8nk4+Ojdu3aac6cOVqyZIlplVGSXn/9dfXv318NGzbUp59+qtWrV2vNmjW66667sl1Rla58Pzmxa9cunT59WpK0Z8+eHJ0LAMDfkTQCgBto3bq1Dh8+rOjo6H8dGxYWpoyMDB08eNBpf1xcnOLj4x0roeaGIkWKOK00munv1UxJstlsatq0qd5++23t27dP48aN0/r16/Xtt99e89qZcR44cCDLsZ9//lm33Xab/Pz8ru8GTDz11FPatWuXzp8/f83FgzJ98cUXatKkiWbOnKkOHTqoWbNmioiIyPKdZDeBz46LFy+qa9euqlKlinr06KEJEyZo27ZtuXZ9AMCth6QRANzAoEGD5Ofnp+7duysuLi7L8cOHD+udd96RdKW9UlKWFU7ffvttSVKrVq1yLa7y5csrISFB//vf/xz7Tp06pSVLljiNO3fuXJZzM19y//fXgGQqUaKEatSooTlz5jglYT/99JO++eYbx33eCE2aNNGYMWP07rvvKiQkxHSch4dHlirmokWL9Pvvvzvty0xur5Vg59Qrr7yi48ePa86cOXr77bdVpkwZRUZGmn6PAAD8G0+rAwAAXL/y5ctr/vz5evLJJ1W5cmV17txZVatWVUpKijZv3qxFixapS5cukqS7775bkZGR+uCDDxQfH69GjRrpxx9/1Jw5c9S2bVvT1zm4okOHDnrllVf06KOPqnfv3rp06ZLee+893XnnnU4LwYwePVobN25Uq1atFBYWptOnT2v69OkqWbKk6tevb3r9N998Uy1atFB4eLi6deumy5cva+rUqQoICNDIkSNz7T7+zmazaejQof86rnXr1ho9erS6du2q++67T3v27NG8efNUrlw5p3Hly5dXYGCgZsyYocKFC8vPz09169ZV2bJlcxTX+vXrNX36dI0YMcLxCpBZs2apcePGGjZsmCZMmJCj6wEAIFFpBAC38cgjj+h///ufHnvsMX355Zfq1auXBg8erKNHj2rixImaMmWKY+xHH32kUaNGadu2berbt6/Wr1+vIUOGaMGCBbkaU7FixbRkyRIVLFhQgwYN0pw5czR+/Hg9/PDDWWIvXbq0Pv74Y/Xq1UvTpk1Tw4YNtX79egUEBJhePyIiQqtWrVKxYsU0fPhwvfXWW6pXr55++OGHHCdcN8Krr76ql19+WatXr1afPn20c+dOff311ypVqpTTOC8vL82ZM0ceHh564YUX1LFjR23YsCFHc50/f17PPvusatasqddee82xv0GDBurTp48mTpyoLVu25Mp9AQBuLYY9J0//AwAAAABuKVQaAQAAAACmSBoBAAAAAKZIGgEAAAAApkgaAQAAAACmSBoBAAAAAKZIGgEAAAAApjytDuBWlpGRoZMnT6pw4cIyDMPqcAAAAIB/ZLfbdf78eYWGhspmyz/1p6SkJKWkpFgdhiTJ29tbvr6+VoeRIySNFjp58mSWFzwDAAAAed2JEydUsmRJq8PIlqSkJBUoXExKu2R1KJKkkJAQHTlyJF8ljiSNFipcuLAkybvWizI8fCyOBgDcyy/LhlkdAgC4nfPnE1X1jjKO32Pzg5SUFCntknyqREoe3tYGk56i2H1zlJKSQtKI7MlsSTU8fGR4kjQCQG7y9/e3OgQAcFv58tEqT18ZFieNdiP/tPReLX9GDQAAAAC4KUgaAQAAAACmaE8FAAAA4P4MSVa31ebDrl6JSiMAAAAA4B+QNAIAAAAATNGeCgAAAMD9GbYrm9Ux5EP5M2oAAAAAwE1B0ggAAAAAMEV7KgAAAAD3Zxh5YPXU/Ll8KpVGAAAAAIApKo0AAAAA3B8L4bgsf0YNAAAAAG7u/Pnz6tu3r8LCwlSgQAHdd9992rZtm+O43W7X8OHDVaJECRUoUEARERE6ePCg0zXOnTunTp06yd/fX4GBgerWrZsuXLiQozhIGgEAAAAgD+revbvWrFmjuXPnas+ePWrWrJkiIiL0+++/S5ImTJigKVOmaMaMGdq6dav8/PzUvHlzJSUlOa7RqVMn7d27V2vWrNHy5cu1ceNG9ejRI0dxGHa73Z6rd4ZsS0xMVEBAgHzu6SfD08fqcADArZxaN9bqEADA7SQmJiospKgSEhLk7+9vdTjZ4vidu/ZLMjys/Z3bnp6s5B1Ts/X9Xb58WYULF9aXX36pVq1aOfbXrl1bLVq00JgxYxQaGqqXX35ZAwYMkCQlJCQoODhYs2fPVocOHbR//35VqVJF27ZtU506dSRJq1atUsuWLfXbb78pNDQ0W3FTaQQAAACAmygxMdFpS05OzjImLS1N6enp8vX1ddpfoEABbdq0SUeOHFFsbKwiIiIcxwICAlS3bl1FR0dLkqKjoxUYGOhIGCUpIiJCNptNW7duzXa8JI0AAAAAcBOVKlVKAQEBjm38+PFZxhQuXFjh4eEaM2aMTp48qfT0dH366aeKjo7WqVOnFBsbK0kKDg52Oi84ONhxLDY2VkFBQU7HPT09VbRoUceY7GD1VAAAAAC3gDyweupfNbsTJ044taf6+Fy7bXbu3Ll69tlndfvtt8vDw0O1atVSx44dtWPHjpsSbSarvzUAAAAAuKX4+/s7bWZJY/ny5bVhwwZduHBBJ06c0I8//qjU1FSVK1dOISEhkqS4uDinc+Li4hzHQkJCdPr0aafjaWlpOnfunGNMdpA0AgAAAHB/hpE3Nhf4+fmpRIkS+vPPP7V69Wq1adNGZcuWVUhIiNatW+cYl5iYqK1btyo8PFySFB4ervj4eKfK5Pr165WRkaG6detme37aUwEAAAAgD1q9erXsdrsqVqyoQ4cOaeDAgapUqZK6du0qwzDUt29fjR07VnfccYfKli2rYcOGKTQ0VG3btpUkVa5cWQ899JCee+45zZgxQ6mpqYqKilKHDh2yvXKqRNIIAAAAAHlSQkKChgwZot9++01FixZV+/btNW7cOHl5eUmSBg0apIsXL6pHjx6Kj49X/fr1tWrVKqcVV+fNm6eoqCg1bdpUNptN7du315QpU3IUB+9ptBDvaQSAG4f3NAJA7svX72m8p7/lv3Pb05KVvO3tfPX9STzTCAAAAAD4BySNAAAAAABTPNMIAAAAwP1dx+qluRpDPkSlEQAAAABgikojAAAAAPdn2K5sVseQD+XPqAEAAAAANwVJIwAAAADAFO2pAAAAANwfC+G4jEojAAAAAMAUSSMAAAAAwBTtqQAAAADcH6unuix/Rg0AAAAAuCmoNAIAAABwf4ZhfaWPhXAAAAAAAO6GpBEAAAAAYIr2VAAAAADuz2Zc2ayOIR+i0ggAAAAAMEXSCAAAAAAwRXsqAAAAAPfHexpdlj+jBgAAAADcFFQaAQAAALg/w7D+PYlWz+8iKo0AAAAAAFMkjQAAAAAAU7SnAgAAAHB/LITjsvwZNQAAAADgpiBpBAAAAACYoj0VAAAAgPtj9VSXUWkEAAAAAJgiaQQAAAAAmKI9FQAAAID7Y/VUl+XPqAEAAAAANwWVRgAAAADuj4VwXEalEQAAAABgiqQRAAAAAGCK9lQAAAAA7o+FcFyWP6MGAAAAANwUJI0AAAAAAFO0pwIAAABwf6ye6jIqjQAAAAAAU1QaAQAAANwC8sBCOPm0Zpc/owYAAAAA3BQkjQAAAAAAU7SnAgAAAHB/LITjMiqNAAAAAABTJI0AAAAAAFO0pwIAAABwf4Zh/eqptKcCAAAAANwNlUYAAAAA7s/IA+9ptHp+F+XPqAEAAAAANwVJIwAAAADAFO2pAAAAANwf72l0GZVGAAAAAIApkkYAAAAAgCnaUwEAAAC4P1ZPdVn+jBoAAAAAcFNQaQQAAADg/lgIx2VUGgEAAAAApkgaAQAAAACmaE8FAAAA4P5YCMdl+TNqAAAAAMBNQdIIAAAAADBFeyoAAAAA98fqqS6j0ggAAAAAMEWlEQAAAIDbMwxDhtWVPqvndxGVRgAAAACAKZJGAAAAAIAp2lMBAAAAuD3aU11HpREAAAAAYIqkEQAAAABgivZUAAAAAO7P+GuzOoZ8iEojAAAAAOQx6enpGjZsmMqWLasCBQqofPnyGjNmjOx2u2OM3W7X8OHDVaJECRUoUEARERE6ePCg03XOnTunTp06yd/fX4GBgerWrZsuXLiQo1hIGgEAAAAgj/nPf/6j9957T++++67279+v//znP5owYYKmTp3qGDNhwgRNmTJFM2bM0NatW+Xn56fmzZsrKSnJMaZTp07au3ev1qxZo+XLl2vjxo3q0aNHjmKhPRUAAACA28tvq6du3rxZbdq0UatWrSRJZcqU0WeffaYff/xR0pUq4+TJkzV06FC1adNGkvTJJ58oODhYS5cuVYcOHbR//36tWrVK27ZtU506dSRJU6dOVcuWLfXWW28pNDQ0W7FQaQQAAACAmygxMdFpS05OzjLmvvvu07p16/TLL79Iknbv3q1NmzapRYsWkqQjR44oNjZWERERjnMCAgJUt25dRUdHS5Kio6MVGBjoSBglKSIiQjabTVu3bs12vFQaAQAAALi9vFRpLFWqlNPuESNGaOTIkU77Bg8erMTERFWqVEkeHh5KT0/XuHHj1KlTJ0lSbGysJCk4ONjpvODgYMex2NhYBQUFOR339PRU0aJFHWOyg6QRAAAAAG6iEydOyN/f3/HZx8cny5iFCxdq3rx5mj9/vu666y7FxMSob9++Cg0NVWRk5M0Ml6QRAAAAAG4mf39/p6TxWgYOHKjBgwerQ4cOkqRq1arp2LFjGj9+vCIjIxUSEiJJiouLU4kSJRznxcXFqUaNGpKkkJAQnT592um6aWlpOnfunOP87OCZRgAAAABuL7M91eotuy5duiSbzTld8/DwUEZGhiSpbNmyCgkJ0bp16xzHExMTtXXrVoWHh0uSwsPDFR8frx07djjGrF+/XhkZGapbt262Y6HSCAAAAAB5zMMPP6xx48apdOnSuuuuu7Rr1y69/fbbevbZZyVdSYL79u2rsWPH6o477lDZsmU1bNgwhYaGqm3btpKkypUr66GHHtJzzz2nGTNmKDU1VVFRUerQoUO2V06VSBoBAAAAIM+ZOnWqhg0bphdffFGnT59WaGionn/+eQ0fPtwxZtCgQbp48aJ69Oih+Ph41a9fX6tWrZKvr69jzLx58xQVFaWmTZvKZrOpffv2mjJlSo5iMex2uz3X7gw5kpiYqICAAPnc00+GZ9aHXwEArju1bqzVIQCA20lMTFRYSFElJCT86zN5eUXm79yF278vw6uApbHYUy/r/H+fz1ffn8QzjQAAAACAf0B7KgAAAAD3Z/y1WR1DPkSlEQAAAABgiqQRAAAAAGCK9lQAAAAAbi+n70m8QUFYO7+LqDQCAAAAAEyRNAIAAAAATNGeCgAAAMDtGYbyQHuqtdO7ikojAAAAAMAUlUYAAAAAbs9QHlgIJ5+WGqk0AgAAAABMkTQCAAAAAEzRngoAAADA7fGeRtdRaQQAAAAAmCJpBAAAAACYoj0VAAAAgPszZP3ipVbP7yIqjQAAAAAAU1QaAQAAALi/PLAQjp2FcAAAAAAA7oakEQAAAABgivZUAAAAAG4vL7yn0er5XUWlEQAAAABgiqQRAAAAAGCK9lQAAAAAbo/2VNdRaQQAAAAAmKLSCAAAAMD9GX9tVseQD1FpBAAAAACYImkEAAAAAJiiPRUAAACA22MhHNdRaQQAAAAAmCJpBAAAAACYoj0VAAAAgNujPdV1VBoBAAAAAKaoNAIAAABwe1QaXUelEQAAAABgiqQRAAAAAGCK9lQAAAAAbo/2VNdRaQQAAAAAmCJpBAAAAACYoj0VAAAAgPsz/tqsjiEfotIIAAAAADBF0ggAAAAAMEV7KgAAAAC3x+qprqPSCAAAAAAwRaURAAAAgNuj0ug6Ko0AAAAAAFMkjQAAAAAAU7SnAgAAAHB7tKe6jkojAAAAAMAUSSMAAAAAwBTtqQAAAADcn/HXZnUM+RCVRgAAAACAKSqNAAAAANweC+G4jkojAAAAAMAUSSMAAAAAwBTtqQAAAADcHu2prqPSCNzCbDZDw597UPu/GKhz347W3kUDNLjLA05jgooU0gevPaZfvxyis+tH6cu3u6p8yWJOY3y8PTXp5Uf028phOrN2pD4b10lBRQrdzFsBgDzlh00b1aF9G1UuV0pFCnrq66++dDq+bOkStXv4IZUrGaQiBT21Z3dMlmskJSVpQN+XVK5kkEoWD1Dnjo/rdFzcTboDAPh/JI3ALezlpxvpuUfrqt/bX6lGx7c1dPoq9e/UUC8+fp9jzML/PKOytxfV44Pnql6XqToe+6dWTOmmgr5ejjETerdSq/srq9PQeWrW6wOVKO6vBeM7WXFLAJAnXLp4UVWrVdebk6Ze8/jFSxdVL/x+jRwz3vQarw56WatWLNfsTxdo+er1ij11Us90fOxGhQwApmhPBW5h9aqFafn3+7Rq8wFJ0vHYeD0RcbfqVCkpSapQ6jbVrVpatTpN0v4jpyVJvd/8UkeXv6onHrxbs5dtl7+fj7o8XEddRn6uDTt+lST1GPeFdn/WX/feVUo/7j1hzc0BgIUebN5CDzZvYXq8w1NPS5KOHzt6zeMJCQn6dM7H+nD2p2rY+EoHyLvvz1TdmlW17cctuufeerkeM+DuDOWB9tR8+qJGKo3ALWzLnmNqUqeCKpS6TZJUrUKIwu8O0zfRv0iSfLw8JElJKWmOc+x2u1JS0nRf9TKSpJqVbpe3l6fWbzvkGPPLsTM6Hvun6lYtfZPuBADcy+5dO5SamqrGTZo69t1ZsZJKliqtbVu3WBgZgFsRlUbgFvbW3A3y9/PR7s/6KT3DLg+boRHvf6MF38RIkg78lfyNeaG5oiYs0cXLqerd4X6VDA5UyG2FJUkhRQsrOSVNCReSnK59+twFBRcrfLNvCQDcQlxcnLy9vRUQGOi0PygoSHFxsdYEBeRzLITjujxbaTx69KgMw1BMTMx1X6tLly5q27btdV8HcDePNa2mDs1qqMvIzxXeZaq6j/1CfZ9qqE4takmS0tIz1GHIp6pQ6jadWj1C59aPUsNa5bVq8wFlZNgtjh4AAAA3Q56tNJYqVUqnTp3SbbfdZnUogNt6vVcLvTV3gxat/Z8kae+vcSodEqiBnRtp3sqdkqRdB06qXpep8vfzkbeXp/6Iv6iNH76oHT//JkmKPXdePt6eCijk61RtDCpaSHFnz9/8mwIANxAcHKyUlBQlxMc7VRtPnz6t4OAQ6wIDcEvKs5VGDw8PhYSEyNPz2nmt3W5XWlraNY8ByJ4Cvt7KsDtXDNPTM2Qzsv7TkHgxWX/EX1T5ksVUq9LtWv79fknSrp9/V0pqmprUKe8Ye0fp21Q6pIi2/nT8xt4AALipu2vWlpeXlzZ8t96x7+AvB/TbieO6py6L4AAuMfLIlg9ZmjSuWrVK9evXV2BgoIoVK6bWrVvr8OHDkrK2p3733XcyDEMrV65U7dq15ePjo02bNmnkyJGqUaOG3n//fZUqVUoFCxbUE088oYSEBJfmvXruxYsXq0mTJipYsKDuvvtuRUdHO11n06ZNatCggQoUKKBSpUqpd+/eunjxYu5/UcANsmLTfr0S2UQP3VdRpUMC9UjDKurdob6+2rjXMaZdk6pqULOsyoQWUesGlfX1O920bOM+rfvxoKQryeTsZdv1n96t1LBWOdWsGKoPXntMW/YcY+VUALesCxcuaM/uGMf7F48dO6I9u2N04sSVP6b9ee6c9uyO0c/790mSDh78RXt2xygu9srzigEBAXo68lm99soAfb/hW8Xs3KFez3fTPXXrsXIqgJvO0qTx4sWL6t+/v7Zv365169bJZrPp0UcfVUZGhuk5gwcP1htvvKH9+/erevXqkqRDhw5p4cKFWrZsmVatWqVdu3bpxRdfvO55X3vtNQ0YMEAxMTG688471bFjR0d18/Dhw3rooYfUvn17/e9//9Pnn3+uTZs2KSoqynTe5ORkJSYmOm2AlfpP+kpLvv1J7wxoo5jP+mv8Sy0188sfNeqDNY4xIbf56+PhT2j3Z/01sd/Dmr9qlzqPWOB0nUFTvtaKH37WZ6930prpzyvu7Hl1GPLpzb4dAMgzYnZuV8PwOmoYXkeS9NorA9QwvI7GjxkpSVr59TI1DK+jJ9s9Iknq1vkpNQyvo1kfve+4xusTJqp5i1bq/NQTatWsiYKDQzT3sy9u+r0AgGG32/PMahZ//PGHihcvrj179qhQoUIqW7asdu3apRo1aui7775TkyZNtHTpUrVp08ZxzsiRIzV27FgdO3ZMt99+u6QrlcRWrVrp999/V0hIiLp06aL4+HgtXbr0X+etWrWqjh49qrJly+qjjz5St27dJEn79u3TXXfdpf3796tSpUrq3r27PDw89P77//+P+6ZNm9SoUSNdvHhRvr6+WeYZOXKkRo0alWW/zz39ZHj6XM9XBwD4m1PrxlodAgC4ncTERIWFFFVCQoL8/f2tDidbEhMTFRAQoLAXF8nmU9DSWDKSL+nY9Mfz1fcnWVxpPHjwoDp27Khy5crJ399fZcqUkSQdP27+HFSdOnWy7CtdurQjYZSk8PBwZWRk6MCBA9c1b2YlU5JKlCgh6coD6JK0e/duzZ49W4UKFXJszZs3V0ZGho4cOXLNeYcMGaKEhATHduIErXsAAAAA8jZLV099+OGHFRYWpg8//FChoaHKyMhQ1apVlZKSYnqOn5/fTZvXy8vL8d+Z71TJbGG9cOGCnn/+efXu3TvL9UuXvvYLzX18fOTjQ0URAAAAuNl4T6PrLEsaz549qwMHDujDDz9UgwYNJF1p73TF8ePHdfLkSYWGhkqStmzZIpvNpooVK96weWvVqqV9+/apQoUKLsUMAAAAAPmBZUljkSJFVKxYMX3wwQcqUaKEjh8/rsGDB7t0LV9fX0VGRuqtt95SYmKievfurSeeeEIhIVnfY5Rb877yyiuqV6+eoqKi1L17d/n5+Wnfvn1as2aN3n33XZfuAwAAAADyGsueabTZbFqwYIF27NihqlWrql+/fnrzzTddulaFChXUrl07tWzZUs2aNVP16tU1ffr0Gzpv9erVtWHDBv3yyy9q0KCBatasqeHDhzuqnQAAAADyDsPIG1tOlClTxtFWe/XWq1cvSVJSUpJ69eqlYsWKqVChQmrfvr3i4uKcrnH8+HG1atVKBQsWVFBQkAYOHJjj991b+kxjRESE9u3b57Tv6sVcr/7vxo0b658Weu3Zs6d69ux5zWOzZ8/O0bxlypTJMldgYGCWfffcc4+++eYb05gAAAAAwFXbtm1Tenq64/NPP/2kBx98UI8//rgkqV+/fvr666+1aNEiBQQEKCoqSu3atdMPP/wgSUpPT1erVq0UEhKizZs369SpU+rcubO8vLz0+uuvZzsOS1dPBQAAAABcW/HixRUSEuLYli9frvLly6tRo0ZKSEjQzJkz9fbbb+uBBx5Q7dq1NWvWLG3evFlbtmyRJH3zzTfat2+fPv30U9WoUUMtWrTQmDFjNG3atH9cfPTvSBoBAAAAuL0r7aFZWz1v7nYllsTERKctOTn5X+NPSUnRp59+qmeffVaGYWjHjh1KTU1VRESEY0ylSpVUunRpRUdHS5Kio6NVrVo1BQcHO8Y0b95ciYmJ2rt3b7a/u3yfNI4cOVIxMTFWhwEAAAAA2VKqVCkFBAQ4tvHjx//rOUuXLlV8fLy6dOkiSYqNjZW3t7cCAwOdxgUHBys2NtYx5uqEMfN45rHssvSZRgAAAAC4KVxYiOZGxCBJJ06ckL+/v2N3dt7lPnPmTLVo0cKShTdJGgEAAADgJvL393dKGv/NsWPHtHbtWi1evNixLyQkRCkpKYqPj3eqNsbFxTlePRgSEqIff/zR6VqZq6te6/WEZvJ9eyoAAAAAuLNZs2YpKChIrVq1cuyrXbu2vLy8tG7dOse+AwcO6Pjx4woPD5ckhYeHa8+ePTp9+rRjzJo1a+Tv768qVapke34qjQAAAADcXuZiNFbHkFMZGRmaNWuWIiMj5en5/+lbQECAunXrpv79+6to0aLy9/fXSy+9pPDwcNWrV0+S1KxZM1WpUkXPPPOMJkyYoNjYWA0dOlS9evXKVktsJpJGAAAAAMij1q5dq+PHj+vZZ5/NcmzSpEmy2Wxq3769kpOT1bx5c02fPt1x3MPDQ8uXL1fPnj0VHh4uPz8/RUZGavTo0TmKgaQRAAAAAPKoZs2ayW63X/OYr6+vpk2bpmnTppmeHxYWphUrVlxXDCSNAAAAANyekQdWT7V6flexEA4AAAAAwBRJIwAAAADAFO2pAAAAANyezWbIZrO2P9Ru8fyuotIIAAAAADBFpREAAACA22MhHNdRaQQAAAAAmCJpBAAAAACYoj0VAAAAgNszDEOGxf2hVs/vKiqNAAAAAABTJI0AAAAAAFO0pwIAAABwe6ye6joqjQAAAAAAU1QaAQAAALg9FsJxHZVGAAAAAIApkkYAAAAAgCnaUwEAAAC4PdpTXUelEQAAAABgiqQRAAAAAGCK9lQAAAAAbo/3NLqOSiMAAAAAwBSVRgAAAABuz1AeWAhH+bPUSKURAAAAAGCKpBEAAAAAYIr2VAAAAABuj4VwXEelEQAAAABgiqQRAAAAAGCK9lQAAAAAbs8w8sDqqfm0P5VKIwAAAADAFJVGAAAAAG6PhXBcR6URAAAAAGCKpBEAAAAAYIr2VAAAAABuj4VwXEelEQAAAABgiqQRAAAAAGCK9lQAAAAAbo/VU11HpREAAAAAYIpKIwAAAAC3x0I4rqPSCAAAAAAwRdIIAAAAADBFeyoAAAAA95cHFsKR1fO7iEojAAAAAMAUSSMAAAAAwBTtqQAAAADcHqunuo5KIwAAAADAFEkjAAAAAMAU7akAAAAA3J6RB1ZPtXp+V1FpBAAAAACYotIIAAAAwO2xEI7rqDQCAAAAAEyRNAIAAAAATNGeCgAAAMDtsRCO66g0AgAAAABMkTQCAAAAAEzRngoAAADA7bF6quuoNAIAAAAATFFpBAAAAOD2qDS6jkojAAAAAMAUSSMAAAAAwBTtqQAAAADcHu9pdB2VRgAAAACAKZJGAAAAAIAp2lMBAAAAuD1WT3UdlUYAAAAAgCkqjQAAAADcHgvhuI5KIwAAAADAFEkjAAAAAMAU7akAAAAA3B4L4biOSiMAAAAAwBRJIwAAAADAFEkjAAAAALdn6P9XULVsy2HMv//+u55++mkVK1ZMBQoUULVq1bR9+3bHcbvdruHDh6tEiRIqUKCAIiIidPDgQadrnDt3Tp06dZK/v78CAwPVrVs3XbhwIUdxkDQCAAAAQB7z559/6v7775eXl5dWrlypffv2aeLEiSpSpIhjzIQJEzRlyhTNmDFDW7dulZ+fn5o3b66kpCTHmE6dOmnv3r1as2aNli9fro0bN6pHjx45ioWFcAAAAAC4PZthyGbxQjQ5mf8///mPSpUqpVmzZjn2lS1b1vHfdrtdkydP1tChQ9WmTRtJ0ieffKLg4GAtXbpUHTp00P79+7Vq1Spt27ZNderUkSRNnTpVLVu21FtvvaXQ0NDsxZ3tqAEAAAAA1y0xMdFpS05OzjLmq6++Up06dfT4448rKChINWvW1Icffug4fuTIEcXGxioiIsKxLyAgQHXr1lV0dLQkKTo6WoGBgY6EUZIiIiJks9m0devWbMdL0ggAAAAAN1GpUqUUEBDg2MaPH59lzK+//qr33ntPd9xxh1avXq2ePXuqd+/emjNnjiQpNjZWkhQcHOx0XnBwsONYbGysgoKCnI57enqqaNGijjHZQXsqAAAAALeXuRiN1TFI0okTJ+Tv7+/Y7+Pjk2VsRkaG6tSpo9dff12SVLNmTf3000+aMWOGIiMjb0q8mag0AgAAAMBN5O/v77RdK2ksUaKEqlSp4rSvcuXKOn78uCQpJCREkhQXF+c0Ji4uznEsJCREp0+fdjqelpamc+fOOcZkB0kjAAAAAOQx999/vw4cOOC075dfflFYWJikK4vihISEaN26dY7jiYmJ2rp1q8LDwyVJ4eHhio+P144dOxxj1q9fr4yMDNWtWzfbsdCeCgAAAMDtGYYhw+L+1JzM369fP9133316/fXX9cQTT+jHH3/UBx98oA8++MBxrb59+2rs2LG64447VLZsWQ0bNkyhoaFq27atpCuVyYceekjPPfecZsyYodTUVEVFRalDhw7ZXjlVImkEAAAAgDznnnvu0ZIlSzRkyBCNHj1aZcuW1eTJk9WpUyfHmEGDBunixYvq0aOH4uPjVb9+fa1atUq+vr6OMfPmzVNUVJSaNm0qm82m9u3ba8qUKTmKxbDb7fZcuzPkSGJiogICAuRzTz8Znln7mAEArju1bqzVIQCA20lMTFRYSFElJCQ4LeSSl2X+zh0xcZ08C/hZGkva5Yta+3LTfPX9STzTCAAAAAD4BySNAAAAAABTPNMIAAAAwP0ZOVuI5kbFkB9RaQQAAAAAmCJpBAAAAACYoj0VAAAAgNszjCub1THkR1QaAQAAAACmSBoBAAAAAKZoTwUAAADg9oy/fqyOIT+i0ggAAAAAMEWlEQAAAIDbsxlXNqtjyI+oNAIAAAAATJE0AgAAAABM0Z4KAAAAwO0ZhiHD4hclWj2/q6g0AgAAAABMkTQCAAAAAEzRngoAAADA7RnGlc3qGPIjKo0AAAAAAFNUGgEAAAC4PZthyGZxqc/q+V1FpREAAAAAYIqkEQAAAABgivZUAAAAAG6PhXBcR6URAAAAAGCKpBEAAAAAYIr2VAAAAABuzzAMGRb3h1o9v6uoNAIAAAAATFFpBAAAAOD2WAjHdVQaAQAAAACmSBoBAAAAAKZoTwUAAADg9myGIZvF/aFWz+8qKo0AAAAAAFMkjQAAAAAAU7SnAgAAAHB7xl+b1THkR1QaAQAAAACmqDQCAAAAcHuGYciweCEaq+d3FZVGAAAAAIApkkYAAAAAgCnaUwEAAAC4PZtxZbM6hvyISiMAAAAAwBRJIwAAAADAFO2pAAAAANweq6e6jkojAAAAAMAUlUYAAAAAt4R8WuizXLaSxq+++irbF3zkkUdcDgYAAAAAkLdkK2ls27Ztti5mGIbS09OvJx4AAAAAQB6SraQxIyPjRscBAAAAADcMC+G47roWwklKSsqtOAAAAAAAeVCOk8b09HSNGTNGt99+uwoVKqRff/1VkjRs2DDNnDkz1wMEAAAAAFgnx0njuHHjNHv2bE2YMEHe3t6O/VWrVtVHH32Uq8EBAAAAQG6wGXljy49ynDR+8skn+uCDD9SpUyd5eHg49t999936+eefczU4AAAAAIC1cpw0/v7776pQoUKW/RkZGUpNTc2VoAAAAAAAeUOOk8YqVaro+++/z7L/iy++UM2aNXMlKAAAAADITZmrp1q95UfZeuXG1YYPH67IyEj9/vvvysjI0OLFi3XgwAF98sknWr58+Y2IEQAAAABgkRxXGtu0aaNly5Zp7dq18vPz0/Dhw7V//34tW7ZMDz744I2IEQAAAACui5FHtvwox5VGSWrQoIHWrFmT27EAAAAAAPIYl5JGSdq+fbv2798v6cpzjrVr1861oAAAAAAAeUOOk8bffvtNHTt21A8//KDAwEBJUnx8vO677z4tWLBAJUuWzO0YAQAAAOC62AxDNosXorF6flfl+JnG7t27KzU1Vfv379e5c+d07tw57d+/XxkZGerevfuNiBEAAAAAYJEcVxo3bNigzZs3q2LFio59FStW1NSpU9WgQYNcDQ4AAAAAYK0cJ42lSpVSampqlv3p6ekKDQ3NlaAAAAAAIDcZxpXN6hjyoxy3p7755pt66aWXtH37dse+7du3q0+fPnrrrbdyNTgAAAAAgLWyVWksUqSIjKvS4osXL6pu3bry9Lxyelpamjw9PfXss8+qbdu2NyRQAAAAAHCVYRhOOY1VMeRH2UoaJ0+efIPDAAAAAADkRdlKGiMjI290HAAAAACAPCjHC+FcLSkpSSkpKU77/P39rysgAAAAAMhtLITjuhwvhHPx4kVFRUUpKChIfn5+KlKkiNMGAAAAAHAfOU4aBw0apPXr1+u9996Tj4+PPvroI40aNUqhoaH65JNPbkSMAAAAAACL5Lg9ddmyZfrkk0/UuHFjde3aVQ0aNFCFChUUFhamefPmqVOnTjciTgAAAABwmc0wZLO4P9Tq+V2V40rjuXPnVK5cOUlXnl88d+6cJKl+/frauHFj7kYHAAAAALBUjpPGcuXK6ciRI5KkSpUqaeHChZKuVCADAwNzNTgAAAAAyA2ZC+FYveVHOU4au3btqt27d0uSBg8erGnTpsnX11f9+vXTwIEDcz1AAAAAAIB1cpw09uvXT71795YkRURE6Oeff9b8+fO1a9cu9enTJ9cDBAAAAIBb0ciRI2UYhtNWqVIlx/GkpCT16tVLxYoVU6FChdS+fXvFxcU5XeP48eNq1aqVChYsqKCgIA0cOFBpaWk5iuO63tMoSWFhYQoLC7veywAAAADADZOZdFkdQ07dddddWrt2reOzp+f/p3D9+vXT119/rUWLFikgIEBRUVFq166dfvjhB0lSenq6WrVqpZCQEG3evFmnTp1S586d5eXlpddffz3bMWQraZwyZUq2L5hZhQQAAAAAXB9PT0+FhIRk2Z+QkKCZM2dq/vz5euCBByRJs2bNUuXKlbVlyxbVq1dP33zzjfbt26e1a9cqODhYNWrU0JgxY/TKK69o5MiR8vb2zl4M2Rk0adKkbF3MMAySRhccXzVS/v7+VocBAG6lyD1RVocAAG7Hnp5idQhuITEx0emzj4+PfHx8rjn24MGDCg0Nla+vr8LDwzV+/HiVLl1aO3bsUGpqqiIiIhxjK1WqpNKlSys6Olr16tVTdHS0qlWrpuDgYMeY5s2bq2fPntq7d69q1qyZrXizlTRmrpYKAAAAAPmRTS4s6HIDYpCkUqVKOe0fMWKERo4cmWV83bp1NXv2bFWsWFGnTp3SqFGj1KBBA/3000+KjY2Vt7d3ljdYBAcHKzY2VpIUGxvrlDBmHs88ll3X/UwjAAAAACD7Tpw44dRpaFZlbNGiheO/q1evrrp16yosLEwLFy5UgQIFbnicmaxOtgEAAADghvv7KqRWbZLk7+/vtJkljX8XGBioO++8U4cOHVJISIhSUlIUHx/vNCYuLs7xDGRISEiW1VQzP1/rOUkzJI0AAAAAkA9cuHBBhw8fVokSJVS7dm15eXlp3bp1juMHDhzQ8ePHFR4eLkkKDw/Xnj17dPr0aceYNWvWyN/fX1WqVMn2vLSnAgAAAEAeNGDAAD388MMKCwvTyZMnNWLECHl4eKhjx44KCAhQt27d1L9/fxUtWlT+/v566aWXFB4ernr16kmSmjVrpipVquiZZ57RhAkTFBsbq6FDh6pXr17Zrm5KJI0AAAAAbgGGIdmsfU2jcvqaxt9++00dO3bU2bNnVbx4cdWvX19btmxR8eLFJV15y4XNZlP79u2VnJys5s2ba/r06Y7zPTw8tHz5cvXs2VPh4eHy8/NTZGSkRo8enaM4XEoav//+e73//vs6fPiwvvjiC91+++2aO3euypYtq/r167tySQAAAADAVRYsWPCPx319fTVt2jRNmzbNdExYWJhWrFhxXXHk+JnG//73v2revLkKFCigXbt2KTk5WdKVl0u+/vrr1xUMAAAAACBvyXHSOHbsWM2YMUMffvihvLy8HPvvv/9+7dy5M1eDAwAAAIDcYDPyxpYf5ThpPHDggBo2bJhlf0BAQJblXgEAAAAA+VuOk8aQkBAdOnQoy/5NmzapXLlyuRIUAAAAAOQmq9/PePV7GvObHCeNzz33nPr06aOtW7fKMAydPHlS8+bN04ABA9SzZ88bESMAAAAAwCI5Xj118ODBysjIUNOmTXXp0iU1bNhQPj4+GjBggF566aUbESMAAAAAwCI5ThoNw9Brr72mgQMH6tChQ7pw4YKqVKmiQoUK3Yj4AAAAAOC65YWFaKye31UuvadRkry9vVWlSpXcjAUAAAAAkMfkOGls0qTJPz7AuX79+usKCAAAAACQd+Q4aaxRo4bT59TUVMXExOinn35SZGRkbsUFAAAAALnGMK5sVseQH+U4aZw0adI1948cOVIXLly47oAAAAAAAHlHjl+5Yebpp5/Wxx9/nFuXAwAAAIBcYzOMPLHlR7mWNEZHR8vX1ze3LgcAAAAAyANy3J7arl07p892u12nTp3S9u3bNWzYsFwLDAAAAABgvRwnjQEBAU6fbTabKlasqNGjR6tZs2a5FhgAAAAA5BabcrHN8jpiyI9ylDSmp6era9euqlatmooUKXKjYgIAAAAA5BE5SnY9PDzUrFkzxcfH36BwAAAAAAB5SY4rpFWrVtWvv/56I2IBAAAAgBsi8z2NVm/5UY6TxrFjx2rAgAFavny5Tp06pcTERKcNAAAAAOA+sv1M4+jRo/Xyyy+rZcuWkqRHHnlExlWpst1ul2EYSk9Pz/0oAQAAAACWyHbSOGrUKL3wwgv69ttvb2Q8AAAAAJDrbDJks7g/1Kb82Z+a7aTRbrdLkho1anTDggEAAAAA5C05euWGkV+f3AQAAABwS8sLC9FYPb+rcpQ03nnnnf+aOJ47d+66AgIAAAAA5B05ShpHjRqlgICAGxULAAAAACCPyVHS2KFDBwUFBd2oWAAAAADghrAZVzarY8iPsv2eRp5nBAAAAIBbT7aTxszVUwEAAAAAt45st6dmZGTcyDgAAAAA4IYxDFn+nsb82ryZ7UojAAAAAODWk6OFcAAAAAAgP+I9ja6j0ggAAAAAMEXSCAAAAAAwRXsqAAAAALfHexpdR6URAAAAAGCKpBEAAAAAYIr2VAAAAABuz/jrx+oY8iMqjQAAAAAAU1QaAQAAALg9FsJxHZVGAAAAAIApkkYAAAAAgCnaUwEAAAC4PdpTXUelEQAAAABgiqQRAAAAAGCK9lQAAAAAbs8wDBmGxe9ptHh+V1FpBAAAAACYotIIAAAAwO2xEI7rqDQCAAAAAEyRNAIAAAAATNGeCgAAAMDtGcaVzeoY8iMqjQAAAAAAUySNAAAAAABTtKcCAAAAcHs2w5DN4v5Qq+d3FZVGAAAAAIApKo0AAAAA3B7vaXQdlUYAAAAAgCmSRgAAAACAKdpTAQAAALi/PPCeRlk9v4uoNAIAAAAATJE0AgAAAABM0Z4KAAAAwO3ZZMhmcX+o1fO7ikojAAAAAMAUSSMAAAAAwBTtqQAAAADcnpEHVk+1en5XUWkEAAAAAJii0ggAAADA7dmMK5vVMeRHVBoBAAAAAKZIGgEAAAAApmhPBQAAAOD2bIYhm8Ur0Vg9v6uoNAIAAAAATJE0AgAAAEAe98Ybb8gwDPXt29exLykpSb169VKxYsVUqFAhtW/fXnFxcU7nHT9+XK1atVLBggUVFBSkgQMHKi0tLUdzkzQCAAAAcHuZ72m0enPFtm3b9P7776t69epO+/v166dly5Zp0aJF2rBhg06ePKl27do5jqenp6tVq1ZKSUnR5s2bNWfOHM2ePVvDhw/P0fwkjQAAAACQR124cEGdOnXShx9+qCJFijj2JyQkaObMmXr77bf1wAMPqHbt2po1a5Y2b96sLVu2SJK++eYb7du3T59++qlq1KihFi1aaMyYMZo2bZpSUlKyHQNJIwAAAAC3Z5PhWAzHsk1XSo2JiYlOW3JysmncvXr1UqtWrRQREeG0f8eOHUpNTXXaX6lSJZUuXVrR0dGSpOjoaFWrVk3BwcGOMc2bN1diYqL27t2bg+8OAAAAAHDTlCpVSgEBAY5t/Pjx1xy3YMEC7dy585rHY2Nj5e3trcDAQKf9wcHBio2NdYy5OmHMPJ55LLt45QYAAAAA3EQnTpyQv7+/47OPj881x/Tp00dr1qyRr6/vzQwvCyqNAAAAANye1QvgXL0Qjr+/v9N2raRxx44dOn36tGrVqiVPT095enpqw4YNmjJlijw9PRUcHKyUlBTFx8c7nRcXF6eQkBBJUkhISJbVVDM/Z47JDpJGAAAAAMhjmjZtqj179igmJsax1alTR506dXL8t5eXl9atW+c458CBAzp+/LjCw8MlSeHh4dqzZ49Onz7tGLNmzRr5+/urSpUq2Y6F9lQAAAAAyGMKFy6sqlWrOu3z8/NTsWLFHPu7deum/v37q2jRovL399dLL72k8PBw1atXT5LUrFkzValSRc8884wmTJig2NhYDR06VL169bpmddMMSSMAAAAAt2eT9W2WuT3/pEmTZLPZ1L59eyUnJ6t58+aaPn2647iHh4eWL1+unj17Kjw8XH5+foqMjNTo0aNzNA9JIwAAAADkA999953TZ19fX02bNk3Tpk0zPScsLEwrVqy4rnlJGgEAAAC4PcMwZGSuRGNhDPmR1RVaAAAAAEAeRtIIAAAAADBFeyoAAAAAt2f8tVkdQ35EpREAAAAAYIqkEQAAAABgivZUAAAAAG7PZhiyWbx6qdXzu4pKIwAAAADAFJVGAAAAALeE/Fnnsx6VRgAAAACAKZJGAAAAAIAp2lMBAAAAuD3DuLJZHUN+RKURAAAAAGCKpBEAAAAAYIr2VAAAAABuzzAMGRb3h1o9v6uoNAIAAAAATFFpBAAAAOD2bLK+Ymb1/K7Kr3EDAAAAAG4CkkYAAAAAgCnaUwEAAAC4PRbCcR2VRgAAAACAKZJGAAAAAIAp2lMBAAAAuD3jr83qGPIjKo0AAAAAAFMkjQAAAAAAU7SnAgAAAHB7rJ7qOiqNAAAAAABTVBoBAAAAuD2brK+YWT2/q/Jr3AAAAACAm4CkEQAAAABgivZUAAAAAG6PhXBcR6URAAAAAGCKpBEAAAAAYIr2VAAAAABuz/hrszqG/IhKIwAAAADAFJVGAAAAAG7PMK5sVseQH1FpBAAAAACYImkEAAAAAJiiPRUAAACA27PJkM3ipWisnt9VVBoBAAAAAKZIGgEAAAAApmhPBQAAAOD2WD3VdVQaAQAAAACmqDQCAAAAcHvGXz9Wx5AfUWkEAAAAAJgiaQQAAAAAmKI9FQAAAIDbYyEc11FpBAAAAACYImkEAAAAAJiiPRUAAACA2zNkyMbqqS6h0ggAAAAAMEWlEQAAAIDbYyEc11FpBAAAAACYImkEAAAAAJiiPRUAAACA26M91XVUGgEAAAAApkgaAQAAAACmaE8FAAAA4PaMv36sjiE/otIIAAAAADBFpREAAACA27MZVzarY8iPqDQCAAAAAEyRNAIAAAAATNGeCgAAAMDtsRCO66g0AgAAAABMkTQCAAAAAEzRngoAAADA7RnGlc3qGPIjKo0AAAAAAFMkjQAAAAAAU7SnAgAAAHB7hqxfvTSfdqdSaQQAAAAAmKPSCAAAAMDt2Ywrm9Ux5EdUGgEAAAAgD3rvvfdUvXp1+fv7y9/fX+Hh4Vq5cqXjeFJSknr16qVixYqpUKFCat++veLi4pyucfz4cbVq1UoFCxZUUFCQBg4cqLS0tBzFQdIIAAAAAHlQyZIl9cYbb2jHjh3avn27HnjgAbVp00Z79+6VJPXr10/Lli3TokWLtGHDBp08eVLt2rVznJ+enq5WrVopJSVFmzdv1pw5czR79mwNHz48R3EYdrvdnqt3hmxLTExUQECA4s4myN/f3+pwAMCtFLknyuoQAMDt2NNTlLznQyUk5J/fXzN/516546j8Clkb88ULiWpRu8x1fX9FixbVm2++qccee0zFixfX/Pnz9dhjj0mSfv75Z1WuXFnR0dGqV6+eVq5cqdatW+vkyZMKDg6WJM2YMUOvvPKKzpw5I29v72zNSaURgEPFCmVUwMvIsvV9qZckKTY2Vs9GPqMyJUNULMBP4ffU0pLF/7U4agDImwoV9NGbA9rrwIrROhf9tr6d3V+1q5SWJHl62jS2dxttW/iq/tg8Ub9+M04fjXlGJYoHOM4vXaKo3hvxlPYvH6lz0W9r71cjNPSFlvLy9LDqlgDkksTERKctOTn5X89JT0/XggULdPHiRYWHh2vHjh1KTU1VRESEY0ylSpVUunRpRUdHS5Kio6NVrVo1R8IoSc2bN1diYqKjWpkdLIQDwGFT9Dalp6c7Pu/b+5NaPfSg2j32uCSpe9fOio+P16LFX+m2227T5wvm6+mOT+iHLdtVo2ZNq8IGgDzpveFPqUqFUD07dI5OnUlQx5b36usZL6lW+7G6cDlZNSqX0hsfrtT/fvldRfwL6q2Bj2nR5OdVv9MESVLFssGyGTZFjV2gwyfO6K4KoZo2rKP8CvhoyKQlFt8dgOtRqlQpp88jRozQyJEjrzl2z549Cg8PV1JSkgoVKqQlS5aoSpUqiomJkbe3twIDA53GBwcHKzY2VtKVP/hfnTBmHs88ll0kjQAcihcv7vT5rQlvqFz58mrQsJEkaUv0Zk159z3dc++9kqTBrw7V1HcmadfOHSSNAHAVXx8vtW1aQ4/3+0A/7DwsSRr3/gq1bFhVzz3eQKOmL1frnu86ndPvjYXaNG+QSoUU0YnYP7Vm836t2bzfcfzo72d1Z1iQnnu8AUkj4ALDuLJZHYMknThxwqk91cfHx/ScihUrKiYmRgkJCfriiy8UGRmpDRs23OhQndCeCuCaUlJStGD+p4rs8qyMv/6Fqxd+n75Y9LnOnTunjIwMLfx8gZKSktSwUWNrgwWAPMbTwyZPTw8lpaQ67U9KTtV9Nctf8xz/wgWUkZGh+POXTa/rX6iAziVeytVYAdx8mauhZm7/lDR6e3urQoUKql27tsaPH6+7775b77zzjkJCQpSSkqL4+Hin8XFxcQoJCZEkhYSEZFlNNfNz5pjsIGkEcE1ffblU8fHxerpzF8e+Tz9bqNTUVN0eXEwBfj566cXn9fkXS1S+QgXrAgWAPOjCpWRt2f2rhjzXQiWKB8hmM9Sh5T2qW72sQm7LuviFj7enxvZuo4Wrduj8xaRrXrNcqdvUs0Mjzfxi040OH3BLRh7ZrldGRoaSk5NVu3ZteXl5ad26dY5jBw4c0PHjxxUeHi5JCg8P1549e3T69GnHmDVr1sjf319VqlTJ9py3ZNLYuHFj9e3b1/R4mTJlNHny5Bxfd+TIkapRo4bLcQF5yZxZM9X8oRYKDQ117Bs1Ypji4+O1YvVa/bBlu3r37a+nOz6hn/bssTBSAMibnh36iQxD+vWbcUrYOlm9OjbSwlXblZHhvHC9p6dNn07oJsMw1Pv1z695rdDiAfrq3V5avHaXZi3ZfDPCB5AHDBkyRBs3btTRo0e1Z88eDRkyRN999506deqkgIAAdevWTf3799e3336rHTt2qGvXrgoPD1e9evUkSc2aNVOVKlX0zDPPaPfu3Vq9erWGDh2qXr16/WN18+94pvEatm3bJj8/P6vDACxz7NgxrV+3VgsWLXbs+/XwYc2Y/q52xPykKnfdJUmqfvfd+mHT93r/vWmaOn2GVeECQJ505Lc/1Kz7Oyro6y3/Qr6K/SNRc9/oqiO//+EY4+lp07z/dFPpEkXUosfUa1YZSxQP0KoP+2jL/35VrzGf3cxbAGCx06dPq3Pnzjp16pQCAgJUvXp1rV69Wg8++KAkadKkSbLZbGrfvr2Sk5PVvHlzTZ8+3XG+h4eHli9frp49eyo8PFx+fn6KjIzU6NGjcxQHSeM1/H0xkL9LTU2Vl5fXTYoGuPnmzpmloKAgtWjZyrHv0qUrz9DYbM4NCh4eHsrIyLip8QFAfnIpKUWXklIUWLiAIu6rrNcmfynp/xPG8qWL66EeU3Qu4WKWc0P/Shh37T+uHiM+Fa/XBlxnkyGbxSvh2HLYoDpz5sx/PO7r66tp06Zp2rRppmPCwsK0YsWKHM37d7dke6okpaWlKSoqSgEBAbrttts0bNgwxz/Ef29PNQxD7733nh555BH5+flp3LhxkqQ33nhDwcHBKly4sLp166akpGs/gwDkJxkZGfpkzix1eiZSnp7//3elipUqqXyFCop68Xlt+/FH/Xr4sCZPmqh1a9fo4TZtrQsYAPKoiPDKevC+ygoLLaYH6lbSqg/76Jcjcfrkq2h5eto0/83uqlWltLq+NkceNkPBxQoruFhhx3sYQ4sHaPVHfXQi9pyGvL1ExYsUcowBgJvplq00zpkzR926ddOPP/6o7du3q0ePHipdurSee+65a44fOXKk3njjDU2ePFmenp5auHChRo4cqWnTpql+/fqaO3eupkyZonLlypnOmZyc7PTizsTExFy/L+B6rV+3VieOH1dkl2ed9nt5eWnpVys09LXBeuzRh3XhwgWVL19BH308Rw+1aGlRtACQdwUU8tXolx7R7cGBOpdwSV+ui9GIacuUlpah0iWK6uHG1SVJP34+xOm8Zt3f0fc7DuqBepVUoXSQKpQO0uFvxjmNKVAz6qbdBwAY9luwz6Fx48Y6ffq09u7d63iVwODBg/XVV19p3759KlOmjPr27etYLMcwDPXt21eTJk1yXOO+++5TzZo1nUrB9erVU1JSkmJiYq4578iRIzVq1Kgs++POJji9pwUAcP2K3MMv1QCQ2+zpKUre86ESEvLP76+JiYkKCAjQ2p3H5FfY2pgvnk9URK2wfPX9Sbdwe2q9evUcCaN0ZTnagwcPKj09/Zrj69Sp4/R5//79qlu3rtO+zKVtzQwZMkQJCQmO7cSJEy5GDwAAAAA3xy3bnppTubGaqo+PT46WtgUAAACQS3LrRYnXG0M+dMtWGrdu3er0ecuWLbrjjjvk4eGRrfMrV658zWsAAAAAgDu5ZZPG48ePq3///jpw4IA+++wzTZ06VX369Mn2+X369NHHH3+sWbNm6ZdfftGIESO0d+/eGxgxAAAAANx8t2x7aufOnXX58mXde++98vDwUJ8+fdSjR49sn//kk0/q8OHDGjRokJKSktS+fXv17NlTq1evvoFRAwAAAHCF8deP1THkR7fk6ql5ReZKTqyeCgC5j9VTASD35efVU9ftOp4nVk9tWrN0vvr+pFu4PRUAAAAA8O9u2fZUAAAAALcQQzKs7g61en4XUWkEAAAAAJii0ggAAADA7fGaRtdRaQQAAAAAmCJpBAAAAACYoj0VAAAAgPujP9VlVBoBAAAAAKZIGgEAAAAApmhPBQAAAOD2jL9+rI4hP6LSCAAAAAAwRaURAAAAgNszjCub1THkR1QaAQAAAACmSBoBAAAAAKZoTwUAAADg9nhNo+uoNAIAAAAATJE0AgAAAABM0Z4KAAAAwP3Rn+oyKo0AAAAAAFMkjQAAAAAAU7SnAgAAAHB7xl8/VseQH1FpBAAAAACYotIIAAAAwO0ZxpXN6hjyIyqNAAAAAABTJI0AAAAAAFO0pwIAAABwe7ym0XVUGgEAAAAApkgaAQAAAACmaE8FAAAA4P7oT3UZlUYAAAAAgCkqjQAAAADcnvHXj9Ux5EdUGgEAAAAApkgaAQAAAACmaE8FAAAA4PYM48pmdQz5EZVGAAAAAIApkkYAAAAAgCnaUwEAAAC4PV7T6DoqjQAAAAAAU1QaAQAAALg/So0uo9IIAAAAADBF0ggAAAAAMEV7KgAAAAC3Z/z1Y3UM+RGVRgAAAACAKZJGAAAAAIAp2lMBAAAAuD3DuLJZHUN+RKURAAAAAGCKSiMAAAAAt8drGl1HpREAAAAAYIqkEQAAAABgivZUAAAAAO6P/lSXUWkEAAAAAJgiaQQAAAAAmKI9FQAAAIDbM/76sTqG/IhKIwAAAADAFJVGAAAAAG7PMK5sVseQH1FpBAAAAACYImkEAAAAAJiiPRUAAACA2+M1ja6j0ggAAAAAMEXSCAAAAAAwRXsqAAAAAPdHf6rLqDQCAAAAQB4zfvx43XPPPSpcuLCCgoLUtm1bHThwwGlMUlKSevXqpWLFiqlQoUJq37694uLinMYcP35crVq1UsGCBRUUFKSBAwcqLS0tR7GQNAIAAABAHrNhwwb16tVLW7Zs0Zo1a5SamqpmzZrp4sWLjjH9+vXTsmXLtGjRIm3YsEEnT55Uu3btHMfT09PVqlUrpaSkaPPmzZozZ45mz56t4cOH5ygWw26323PtzpAjiYmJCggIUNzZBPn7+1sdDgC4lSL3RFkdAgC4HXt6ipL3fKiEhPzz+2vm79w7D8aqUGFrY75wPlG17ghx6fs7c+aMgoKCtGHDBjVs2FAJCQkqXry45s+fr8cee0yS9PPPP6ty5cqKjo5WvXr1tHLlSrVu3VonT55UcHCwJGnGjBl65ZVXdObMGXl7e2drbiqNAAAAAHATJSYmOm3Jycn/ek5CQoIkqWjRopKkHTt2KDU1VREREY4xlSpVUunSpRUdHS1Jio6OVrVq1RwJoyQ1b95ciYmJ2rt3b7bjJWkEAAAA4P4MybB4y1wIp1SpUgoICHBs48eP/8fQMzIy1LdvX91///2qWrWqJCk2Nlbe3t4KDAx0GhscHKzY2FjHmKsTxszjmceyi9VTAQAAAOAmOnHihFN7qo+Pzz+O79Wrl3766Sdt2rTpRod2TVQaAQAAAOAm8vf3d9r+KWmMiorS8uXL9e2336pkyZKO/SEhIUpJSVF8fLzT+Li4OIWEhDjG/H011czPmWOyg6QRAAAAgNsz8siWXXa7XVFRUVqyZInWr1+vsmXLOh2vXbu2vLy8tG7dOse+AwcO6Pjx4woPD5ckhYeHa8+ePTp9+rRjzJo1a+Tv768qVapkOxbaUwEAAAAgj+nVq5fmz5+vL7/8UoULF3Y8gxgQEKACBQooICBA3bp1U//+/VW0aFH5+/vrpZdeUnh4uOrVqydJatasmapUqaJnnnlGEyZMUGxsrIYOHapevXr9a0vs1UgaAQAAACCPee+99yRJjRs3dto/a9YsdenSRZI0adIk2Ww2tW/fXsnJyWrevLmmT5/uGOvh4aHly5erZ8+eCg8Pl5+fnyIjIzV69OgcxULSCAAAAMD95bQ/9EbFkE12u/1fx/j6+mratGmaNm2a6ZiwsDCtWLEi+xNfA880AgAAAABMUWkEAAAA4PaMv36sjiE/otIIAAAAADBF0ggAAAAAMEV7KgAAAAC3ZxhXNqtjyI+oNAIAAAAATJE0AgAAAABM0Z4KAAAAwO3ls9c05ilUGgEAAAAApqg0AgAAAHB/lBpdRqURAAAAAGCKpBEAAAAAYIr2VAAAAABuz/jrx+oY8iMqjQAAAAAAUySNAAAAAABTtKcCAAAAcHuGJMPi7tD82ZxKpREAAAAA8A+oNAIAAABwe7ym0XVUGgEAAAAApkgaAQAAAACmaE8FAAAA4PYMIw8shJNP+1OpNAIAAAAATJE0AgAAAABM0Z4KAAAA4BbA+qmuotIIAAAAADBFpREAAACA22MhHNdRaQQAAAAAmCJpBAAAAACYoj0VAAAAgNtjGRzXUWkEAAAAAJgiaQQAAAAAmKI9FQAAAIDbY/VU11FpBAAAAACYotIIAAAAwO0Zf/1YHUN+RKURAAAAAGCKpBEAAAAAYIr2VAAAAADujxc1uoxKIwAAAADAFEkjAAAAAMAU7akAAAAA3B7dqa6j0ggAAAAAMEXSCAAAAAAwRXsqAAAAALdnGFc2q2PIj6g0AgAAAABMUWkEAAAA4PaMv36sjiE/otIIAAAAADBF0ggAAAAAMEV7KgAAAAD3x4saXUalEQAAAABgiqQRAAAAAGCK9lQAAAAAbo/uVNdRaQQAAAAAmKLSCAAAAMDtGcaVzeoY8iMqjQAAAAAAUySNAAAAAABTtKcCAAAAuAUYMixfisbq+V1DpREAAAAAYIqkEQAAAABgivZUAAAAAG6P1VNdR6URAAAAAGCKpBEAAAAAYIqkEQAAAABgiqQRAAAAAGCKhXAAAAAAuD0WwnEdlUYAAAAAgCmSRgAAAACAKdpTAQAAALg9468fq2PIj6g0AgAAAABMUWkEAAAA4PZYCMd1VBoBAAAAAKZIGgEAAAAApkgaAQAAALg9I49sObFx40Y9/PDDCg0NlWEYWrp0qdNxu92u4cOHq0SJEipQoIAiIiJ08OBBpzHnzp1Tp06d5O/vr8DAQHXr1k0XLlzIURwkjQAAAACQB128eFF33323pk2bds3jEyZM0JQpUzRjxgxt3bpVfn5+at68uZKSkhxjOnXqpL1792rNmjVavny5Nm7cqB49euQoDhbCAQAAAIA8qEWLFmrRosU1j9ntdk2ePFlDhw5VmzZtJEmffPKJgoODtXTpUnXo0EH79+/XqlWrtG3bNtWpU0eSNHXqVLVs2VJvvfWWQkNDsxUHlUYAAAAA7s/qvtSr+lMTExOdtuTk5BzfzpEjRxQbG6uIiAjHvoCAANWtW1fR0dGSpOjoaAUGBjoSRkmKiIiQzWbT1q1bsz0XSSMAAAAA3ESlSpVSQECAYxs/fnyOrxEbGytJCg4OdtofHBzsOBYbG6ugoCCn456enipatKhjTHbQngoAAADA7Rl//VgdgySdOHFC/v7+jv0+Pj5WhZQtVBoBAAAA4Cby9/d32lxJGkNCQiRJcXFxTvvj4uIcx0JCQnT69Gmn42lpaTp37pxjTHaQNAIAAABAPlO2bFmFhIRo3bp1jn2JiYnaunWrwsPDJUnh4eGKj4/Xjh07HGPWr1+vjIwM1a1bN9tz0Z4KAAAAwO0ZxpXN6hhy4sKFCzp06JDj85EjRxQTE6OiRYuqdOnS6tu3r8aOHas77rhDZcuW1bBhwxQaGqq2bdtKkipXrqyHHnpIzz33nGbMmKHU1FRFRUWpQ4cO2V45VSJpBAAAAIA8afv27WrSpInjc//+/SVJkZGRmj17tgYNGqSLFy+qR48eio+PV/369bVq1Sr5+vo6zpk3b56ioqLUtGlT2Ww2tW/fXlOmTMlRHIbdbrfnzi0hpxITExUQEKC4swlOD8ICAK5fkXuirA4BANyOPT1FyXs+VEJC/vn9NfN37pNn4i2POTExUaHFA/PV9ydRaQQAAABwC7jqNYmWxpAfsRAOAAAAAMAUSSMAAAAAwBTtqQAAAADcH/2pLqPSCAAAAAAwRaURAAAAgNsz/vqxOob8iEojAAAAAMAUSSMAAAAAwBTtqQAAAADcnmFc2ayOIT+i0ggAAAAAMEWl0UJ2u12SdD4x0eJIAMD92NNTrA4BANxO5r+tmb/H5ieJeeB37rwQgytIGi10/vx5SVKFsqUsjgQAAADIvvPnzysgIMDqMLLF29tbISEhuiOP/M4dEhIib29vq8PIEcOeH/9M4CYyMjJ08uRJFS5cWEZ+bXDGLSMxMVGlSpXSiRMn5O/vb3U4AOA2+PcV+Yndbtf58+cVGhoqmy3/POmWlJSklJS80YHi7e0tX19fq8PIESqNFrLZbCpZsqTVYQA54u/vzy81AHAD8O8r8ov8UmG8mq+vb75L1PKS/PPnAQAAAADATUfSCAAAAAAwRdIIIFt8fHw0YsQI+fj4WB0KALgV/n0FkNexEA4AAAAAwBSVRgAAAACAKZJGAAAAAIApkkYAAAAAgCmSRgAAAACAKZJGAACAPIi1CgHkFSSNAAAAeciePXskSYZhWBwJAFxB0gjghuIv5QCQfatXr1bTpk318ccfWx0KADh4Wh0AAPeVkZEhm+3K36Z+/vlneXl5KSMjQ3fccYfFkQFA3hQaGqr27dtr4sSJMgxDXbt2tTokACBpBHBj2O12R8I4YsQIffnll7p8+bIuX76sfv36qXfv3vLw8LA4SgDIW6pVq6ZXXnlFBQsW1FtvvSVfX1917NjR6rAA3OJoTwVwQ2Q+izNu3DhNmzZNkydP1qZNmxQREaGXX35Zv/zyi8URAkDekp6eLklKTEyUn5+fzp8/r/79++uzzz6zODIAtzqSRgA3TFJSkn788UdNmzZNjRs31g8//KClS5dq+vTpqly5slJTU60OEQDyDA8PDy1evFgNGjRQcnKy2rZtq+DgYA0fPlyzZ8+2OjwAtzDDzioVAG6Qs2fPqmLFilq2bJmSkpL0yCOP6M0339QLL7yg5ORkjR07Vu3bt1eNGjWsDhUALPfnn3+qZcuWatGihYYPHy5JiomJ0Xvvvad169ZpzJgxtKoCsASVRgC5IiMjI8u+YsWK6fHHH9dbb72l1q1ba/LkyXrhhRckSX/88Ye2bdumn3766WaHCgB5Rubf7hMSElSoUCGdOXNGPj4+juM1atRQz5495e3trUGDBmnmzJlWhQrgFkbSCOC6Xb1K6m+//aZjx445jt19993asGGDHnroIT3++OOSrvw1vUePHrp8+TJ/NQdwSzMMQ0uWLNELL7ygY8eO6d5779WRI0d09uxZx5gaNWrovvvuk2EYmjlzpuLj43mdEYCbiqQRwHXLTBhfe+01NWnSROHh4erQoYPi4+P1wgsvqFevXtqzZ48iIiL0yCOPqGXLljp58qTWrl0rDw8Px+IPAHAryMjIcCR9R44c0eDBgxUREaEKFSrogQce0KJFizR//nz98ccfjnO8vLwUFRWlZcuWKTAw0LHYGADcDDzTCMBlV1cY586dq9dee03jxo1Tenq6Ro4cqRIlSmjRokUqWbKkli1bppiYGJ05c0aVKlVSjx495OnpqbS0NHl68vYfAO7vt99+U8mSJR2f169fr5iYGO3bt09TpkxRwYIFJUmjR4/WlClT1LJlS5UqVUpnzpzRkiVLtG3bNpUpU8ai6AHcykgaAVy3lStX6siRIypQoIDjRdQnT55UgwYNVLx4cS1cuFClS5fOcl56ejrvagRwSxgzZox+/fVXvffee/L19ZUkPf/88/rwww9Vvnx5ff/99woJCXGMnzNnjr7//nvt2LFDwcHBeuONN1g0DIBlSBoBXJdTp06pZMmSstvteuONNzRo0CDZ7XYZhqFTp06pQYMGCg0N1QcffKBKlSpZHS4AWCI6OloBAQGqUqWKEhISFBAQIOlKW//48eP17rvvqkuXLo5qo3SlmyM1NVXp6elO+wHgZuOZRgDXpUSJEo6WqTVr1ujs2bMyDEN2u10lSpTQ999/r507d+qdd96xOlQAsITdbld4eLiqVKmi7777Tj169NDmzZslSePGjVPPnj318ssva/HixUpKSnI618fHh4QRgOV4kAhAtl39DOPVatWqpc8//1wtWrTQ888/r5kzZyogIMCROB47dkyBgYE3P2AAyAOuXrTGMAytX79eHh4e8vDwUN26dTVt2jRlZGToueeek81m06OPPqoCBQpc899bALAC7akAsuXvi94cPXpUf/zxhwYOHOhY2OHHH39UixYt9MADD+ijjz5yJI6ZvzDxDCOAW4ndbldGRoY8PDx09uxZeXl5yd/fXz/99JPatGmj2rVr6+WXX1bdunUlSVFRUZo+fboWLFigJ554wuLoAeD/8ScsANmSmTAOHjxYgwcP1s6dO7Vz506Fh4dr+fLlunz5su69916tWrVKGzdu1KOPPqqLFy86/YWdhBHArWDFihXavXu3DMOQh4eHFi9erFatWqlmzZp65JFH9Ntvv2nNmjXasWOHJk6cqK1bt0qS3n33XfXr10/Vq1e3+A4AwBmVRgD/KrNaOGPGDI0bN07Lli1TjRo19O2336pp06YKDg7Wu+++q1atWsnX11c//PCDxo0bp+XLl9NeBeCWEhcXp/DwcDVu3FhDhw5VUlKS6tWrp1deeUWenp46evSoPvroI3300Udq0KCBHnzwQdWtW1cvvvii6tevb3X4AHBNJI0Armno0KG64447FBkZKUlKSEjQtGnTFBISomeffVZLly5VZGSkpk6dqhUrVmjjxo2aNm2amjdvnmX1PxJHALeSnTt36vnnn1fdunUVGBio5ORkvfnmm5KkxMREffLJJ+rfv79WrlypoKAgNWzYUO3bt9e7777reB0HAOQlJI0Asvj111/1/PPPKyUlRVFRUXr88cclSVu3blWpUqV04cIFtW3bVi+88IJ69+6tH374QQ0aNHAs8NCoUSOL7wAArLVz50717NlTcXFxat26td59913HsYSEBPXt21dJSUn67LPPtHnzZgUFBalChQoWRgwA5vjzP4AsypUrpzfeeEMlSpTQ1KlT9fnnn0uS6tatq9DQUP38888qVKiQWrduLUlKS0vTkCFDNHz4cN1///1Whg4AeUKtWrX04YcfyjAMrVu3TjExMY5jAQEBCg0N1b59+5SUlKT77ruPhBFAnkbSCOCaateurYEDB6pEiRKaNm2aFi5c6Dj2+++/6+eff9Yff/yhY8eO6a233tL58+c1YsQIeXp6Ki0tzcLIASBvqF69ur766it5eXnpnXfe0e7dux3H/vjjDwUFBSk9Pd3CCAEge2hPBeCQueDN1a/G+PHHHzVx4kSdOnVKvXr10pNPPilJatSokaKjoxUaGqrAwEBt27ZNXl5eVoYPAHnSrl271LlzZ126dEkNGzaUj4+PvvjiC61du1Y1atSwOjwA+FckjQAkOS9Yc/r0afn6+qpQoUKy2Wzavn27JkyYoFOnTunFF19Ux44dJUmLFi2Sn5+fmjdvLg8PD6WlpcnT09PK2wCAPGnPnj1q166dkpOTHf+OhoWFWR0WAGQLSSMAJyNGjNB///tf2Ww2FStWTFOnTlXVqlUVExOj119/XbGxserZs6cjccx0dXUSAJDVjh07NGTIEM2bN0/Fixe3OhwAyDaSRuAWd3WFcfbs2erXr58mTJiglJQULV26VNu3b9fcuXPVunVr/fjjj5o0aZJ2796tqVOnqmnTphZHDwD5S1JSEq/VAJDvkDQCkCQtW7ZM27ZtU/ny5R3vZpSkyMhILVu2TD/99JNCQ0O1efNmrVq1SiNGjKCyCAAAcAsgaQRuUVe3k27btk2dO3fW0aNH9cEHH+iZZ55RSkqKvL29JUk1a9ZU48aNNWnSJNNrAAAAwD3xyg3gFpWZ7M2bN0+S9Pzzz6t48eKaO3euJMnb21tpaWlKT09XyZIllZycbHoNAAAAuC+SRuAWc/U7wSZOnKhnnnlGxYsX17PPPqvBgwfr6NGjevrppyVJnp6e8vDwUFxcnHx8fKwKGQAAABaiPRW4Re3cuVObN2/W7bffrkcffVSSdOHCBc2ePVtvvPGGihYtqkqVKsnDw0Pbt2/X/v37eZ0GAADALYhKI3ALeO655xQXF+f4vGXLFtWpU0cDBgxQWlqapCurqBYqVEhdu3bVq6++qpSUFO3bt0/dunXTwYMH5enp6RgLAACAWwdJI+DmTp8+rTNnzqho0aKOfdWrV9fkyZPl4eGhnTt3SpIMw1BGRob8/PzUuXNnvfjii/Lz89OCBQsc5xmGcdPjBwAAgLVoTwVuIR9//LGaNm2qsLAwXbp0SdOnT9egQYM0efJk9e7dW9L/v7fx/Pnzmj17tubMmaPy5cvr888/tzh6AAAAWIEHlIBbxPnz5zV48GCVLFlSX331lUqWLKmoqChlZGSob9++stlsioqKks1mU0ZGhgoXLqyuXbvq8uXLWr58uU6dOqUSJUpYfRsAAAC4yag0Am4qs2J4tRMnTqhFixYqUKCAlixZopIlSyopKUlTp07Vq6++qjFjxmjw4MGSJLvdLsMwdOHCBaWmpqpIkSJW3AYAAAAsRtIIuKGrE8a1a9fqwoULstlseuSRR/Tbb7/poYceckock5OTNW7cOK1fv17ff/+949nFzMQRAAAAty6SRsDNXJ3oDRkyRHPnzlVQUJD279+vJ598UmPHjpXdbleLFi1UsGBBLV68WCVLllRqaqo8PT1lGAbJIgAAABxYPRVwM5nJ3oQJEzRnzhwtXrxYO3fu1JtvvqlPPvlEffr0kWEYWrVqlZKTk3X//ffrzJkz8vLyImEEAABAFiSNgBs6efKk9u3bp0mTJunee+/V4sWLNXz4cA0dOlTr1q1Tnz59lJaWpi+//FINGzZ0eh0HCSMAAACuRnsq4IaSkpK0cuVKNWnSRIcOHdLjjz+ufv36qXfv3nr77bc1YMAANW7cWAsWLFBQUJAkKT09XR4eHhZHDgAAgLyGSiPghnx9fdW6dWsFBgZq7dq1uuuuuxQZGSlJ8vb2VqdOneTj46PbbrvNcQ4JIwAAAK6FpBFwU56eV17D+ssvvyghIUGGYSgpKUmrV69W69attXLlSsc7GQEAAAAztKcCbm7Lli1q2LChKlasqOTkZPn6+mrnzp2OpBIAAAD4JySNwC1g586dWrx4sfz9/dW/f395enoqLS2NxBEAAAD/iqQRuAWRMAIAACC7SBoBAAAAAKZYCAcAAAAAYIqkEQAAAABgiqQRAAAAAGCKpBEAAAAAYIqkEQAAAABgiqQRAAAAAGCKpBEAAAAAYIqkEQBgiS5duqht27aOz40bN1bfvn1vehzfffedDMNQfHy86RjDMLR06dJsX3PkyJGqUaPGdcV19OhRGYahmJiY67oOAADXi6QRAODQpUsXGYYhwzDk7e2tChUqaPTo0UpLS7vhcy9evFhjxozJ1tjsJHoAACB3eFodAAAgb3nooYc0a9YsJScna8WKFerVq5e8vLw0ZMiQLGNTUlLk7e2dK/MWLVo0V64DAAByF5VGAIATHx8fhYSEKCwsTD179lRERIS++uorSf/fUjpu3DiFhoaqYsWKkqQTJ07oiSeeUGBgoIoWLao2bdro6NGjjmump6erf//+CgwMVLFixTRo0CDZ7Xanef/enpqcnKxXXnlFpUqVko+PjypUqKCZM2fq6NGjatKkiSSpSJEiMgxDXbp0kSRlZGRo/PjxKlu2rAoUKKC7775bX3zxhdM8K1as0J133qkCBQqoSZMmTnFm1yuvvKI777xTBQsWVLly5TRs2DClpqZmGff++++rVKlSKliwoJ544gklJCQ4Hf/oo49UuXJl+fr6qlKlSpo+fXqOYwEA4EYjaQQA/KMCBQooJSXF8XndunU6cOCA1qxZo+XLlys1NVXNmzdX4cKF9f333+uHH35QoUKF9NBDDznOmzhxombPnq2PP/5YmzZt0rlz57RkyZJ/nLdz58767LPPNGXKFO3fv1/vv/++ChUqpFKlSum///2vJOnAgQM6deqU3nnnHUnS+PHj9cknn2jGjBnau3ev+vXrp6efflobNmyQdCW5bdeunR5++GHFxMSoe/fuGjx4cI6/k8KFC2v27Nnat2+f3nnnHX344YeaNGmS05hDhw5p4cKFWrZsmVatWqVdu3bpxRdfdByfN2+ehg8frnHjxmn//v16/fXXNWzYMM2ZMyfH8QAAcEPZAQD4S2RkpL1NmzZ2u91uz8jIsK9Zs8bu4+NjHzBggON4cHCwPTk52XHO3Llz7RUrVrRnZGQ49iUnJ9sLFChgX716td1ut9tLlChhnzBhguN4amqqvWTJko657Ha7vVGjRvY+ffrY7Xa7/cCBA3ZJ9jVr1lwzzm+//dYuyf7nn3869iUlJdkLFixo37x5s9PYbt262Tt27Gi32+32IUOG2KtUqeJ0/JVXXslyrb+TZF+yZInp8TfffNNeu3Ztx+cRI0bYPTw87L/99ptj38qVK+02m81+6tQpu91ut5cvX94+f/58p+uMGTPGHh4ebrfb7fYjR47YJdl37dplOi8AADcDzzQCAJwsX75chQoVUmpqqjIyMvTUU09p5MiRjuPVqlVzeo5x9+7dOnTokAoXLux0naSkJB0+fFgJCQk6deqU6tat6zjm6empOnXqZGlRzRQTEyMPDw81atQo23EfOnRIly5d0oMPPui0PyUlRTVr1pQk7d+/3ykOSQoPD8/2HJk+//xzTZkyRYcPH9aFCxeUlpYmf39/pzGlS5fW7bff7jRPRkaGDhw4oMKFC+vw4cPq1q2bnnvuOceYtLQ0BQQE5DgeAABuJJJGAICTJk2a6L333pO3t7dCQ0Pl6en8vwo/Pz+nzxcuXFDt2rU1b968LNcqXry4SzEUKFAgx+dcuHBBkvT11187JWvSlec0c0t0dLQ6deqkUaNGqXnz5goICNCCBQs0ceLEHMf64YcfZkliPTw8ci1WAAByA0kjAMCJn5+fKlSokO3xtWrV0ueff66goKAs1bZMJUqU0NatW9WwYUNJVypqO3bsUK1ata45vlq1asrIyNCGDRsUERGR5XhmpTM9Pd2xr0qVKvLx8dHx48dNK5SVK1d2LOqTacuWLf9+k1fZvHmzwsLC9Nprrzn2HTt2LMu448eP6+TJkwoNDXXMY7PZVLFiRQUHBys0NFS//vqrOnXqlKP5AQC42VgIBwBwXTp16qTbbrtNbdq00ffff68jR47ou+++U+/evfXbb79Jkvr06aM33nhDS5cu1c8//6wXX3zxH9+xWKZMGUVGRurZZ5/V0qVLHddcuHChJCksLEyGYWj58uU6c+aMLly4oMKFC2vAgAHq16+f5syZo8OHD2vnzp2aOnWqY3GZF154QQcPHtTAgQN14MABzZ8/X7Nnz87R/d5xxx06fvy4FixYoMOHD2vKlCnXXNTH19dXkZGR2r17t77//nv17t1bTzzxhEJCQiRJo0aN0vjx4zVlyhT98ssv2rNnj2bNmqW33347R/EAAHCjkTQCAK5LwYIFtXHjRpUuXVrt2rVT5cqV1a1bNyUlJTkqjy+//LKeeeYZRUZGKjw8XIULF9ajjz76j9d977339Nhjj+nFF19UpUqV9Nxzz+nixYuSpNtvv12jRo3S4MGDFRwcrKioKEnSmDFjNGzYMI0fP16VK1fWQw89pK+//lply5aVdOU5w//+979aunSp7r77bs2YMUOvv/56ju73kUceUb9+/RQVFaUaNWpo8+bNGjZsWJZxFSpUULt27dSyZUs1a9ZM1atXd3qlRvfu3fXRRx9p1qxZqlatmho1aqTZs2c7YgUAIK8w7GarEAAAAAAAbnlUGgEAAAAApkgaAQAAAACmSBoBAAAAAKZIGgEAAAAApkgaAQAAAACmSBoBAAAAAKZIGgEAAAAApkgaAQAAAACmSBoBAAAAAKZIGgEAAAAApkgaAQAAAACm/g81FsrdY3xRJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_path = \"runs/cifar2_model_best_model.pth\"\n",
    "test_metrics = final_evaluation(NetRes, best_model_path, val_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f5ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
