{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97e8b0f",
   "metadata": {},
   "source": [
    "# Testing multiclass classification and using TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4091f30b",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8503030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x77394c3099f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "from contextlib import contextmanager\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6167f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33ed318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar10/cifar-10-python.tar.gz to ../data/cifar10/\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/cifar10/\"\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2fec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616)),\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b1a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = [\"airplane\", \"bird\"]\n",
    "cifar2 = [(img, label_map[label]) for img, label in cifar10 if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "374962dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2ebbd",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "620edea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    \"\"\"Run one epoch of training.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: Training data loader\n",
    "        optimizer: PyTorch optimizer\n",
    "        loss_fn: Loss function\n",
    "        device: Device to run on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing training metrics\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_train = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total_train += labels.shape[0]\n",
    "        correct_train += int((predicted == labels).sum())\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_loss = loss_train / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    \n",
    "    return {\n",
    "        'loss': train_loss,\n",
    "        'accuracy': train_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8537738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def create_summary_writer(model_name, hyperparams=None):\n",
    "    \"\"\"Context manager for creating and managing a TensorBoard SummaryWriter.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model for the log directory\n",
    "        hyperparams (dict, optional): Hyperparameters to log\n",
    "        \n",
    "    Yields:\n",
    "        SummaryWriter: TensorBoard writer\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    model_architecture = hyperparams.get('model_architecture', '') if hyperparams else ''\n",
    "    log_dir = f\"runs/{model_name}_{model_architecture}_{timestamp}\"\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    \n",
    "    print(f\"TensorBoard logs will be saved to {log_dir}\")\n",
    "    \n",
    "    if hyperparams:\n",
    "        # Log hyperparameters as text\n",
    "        param_str = \"\\n\".join([f\"{k}: {v}\" for k, v in hyperparams.items()])\n",
    "        writer.add_text('Hyperparameters', param_str)\n",
    "    \n",
    "    try:\n",
    "        yield writer\n",
    "    finally:\n",
    "        writer.close()\n",
    "        print(f\"TensorBoard writer closed for {log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d755fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, loss_fn, device, class_names=None):\n",
    "    \"\"\"Evaluate the model on validation data.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        val_loader: Validation data loader\n",
    "        loss_fn: Loss function\n",
    "        device: Device to run on\n",
    "        class_names (list, optional): List of class names\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing validation metrics and predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total_val += labels.shape[0]\n",
    "            correct_val += int((predicted == labels).sum())\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'loss': val_loss,\n",
    "        'accuracy': val_accuracy,\n",
    "        'f1': val_f1,\n",
    "        'predictions': all_preds,\n",
    "        'true_labels': all_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10d75707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(writer, train_metrics, val_metrics, optimizer, epoch):\n",
    "    \"\"\"Log metrics to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        train_metrics (dict): Training metrics\n",
    "        val_metrics (dict): Validation metrics\n",
    "        optimizer: PyTorch optimizer\n",
    "        epoch (int): Current epoch\n",
    "    \"\"\"\n",
    "    # Log scalar metrics\n",
    "    writer.add_scalar('Loss/train', train_metrics['loss'], epoch)\n",
    "    writer.add_scalar('Loss/validation', val_metrics['loss'], epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_metrics['accuracy'], epoch)\n",
    "    writer.add_scalar('Accuracy/validation', val_metrics['accuracy'], epoch)\n",
    "    writer.add_scalar('F1/validation', val_metrics['f1'], epoch)\n",
    "    \n",
    "    # Log learning rate\n",
    "    writer.add_scalar('Learning_Rate', optimizer.param_groups[0]['lr'], epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0009108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_info(writer, model, epoch, train_loader, device):\n",
    "    \"\"\"Log model parameters and gradients to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        model: PyTorch model\n",
    "        epoch (int): Current epoch\n",
    "        train_loader: Training data loader\n",
    "        device: Device to run on\n",
    "    \"\"\"\n",
    "    # Log model graph (only once)\n",
    "    if epoch == 1:\n",
    "        example_images, _ = next(iter(train_loader))\n",
    "        try:\n",
    "            writer.add_graph(model, example_images.to(device))\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to add model graph to TensorBoard: {e}\")\n",
    "    \n",
    "    # Log histograms of model parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        writer.add_histogram(f'Parameters/{name}', param, epoch)\n",
    "        if param.grad is not None:\n",
    "            writer.add_histogram(f'Gradients/{name}', param.grad, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2578a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_predictions(writer, model, val_loader, device, class_names, epoch, num_images=10):\n",
    "    \"\"\"Log prediction visualizations to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        model: PyTorch model\n",
    "        val_loader: Validation data loader\n",
    "        device: Device to run on\n",
    "        class_names (list): List of class names\n",
    "        epoch (int): Current epoch\n",
    "        num_images (int): Number of images to visualize\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            for j in range(imgs.size()[0]):\n",
    "                if images_so_far >= num_images:\n",
    "                    break\n",
    "                \n",
    "                ax = plt.subplot(2, num_images//2, images_so_far + 1)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'pred: {class_names[preds[j]]}\\ntrue: {class_names[labels[j]]}',\n",
    "                           color=(\"green\" if preds[j]==labels[j] else \"red\"))\n",
    "                \n",
    "                # Denormalize and convert to numpy for matplotlib\n",
    "                img = imgs[j].cpu().numpy().transpose((1, 2, 0))\n",
    "                mean = np.array([0.4915, 0.4823, 0.4468])\n",
    "                std = np.array([0.2470, 0.2435, 0.2616])\n",
    "                img = std * img + mean\n",
    "                img = np.clip(img, 0, 1)\n",
    "                \n",
    "                plt.imshow(img)\n",
    "                images_so_far += 1\n",
    "                if images_so_far >= num_images:\n",
    "                    break\n",
    "    \n",
    "    writer.add_figure(f'Predictions/Epoch_{epoch}', fig, epoch)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20991202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_embeddings(writer, model, val_loader, device, class_names, n_epochs):\n",
    "    \"\"\"Log embeddings to TensorBoard.\n",
    "    \n",
    "    Args:\n",
    "        writer: TensorBoard SummaryWriter\n",
    "        model: PyTorch model\n",
    "        val_loader: Validation data loader\n",
    "        device: Device to run on\n",
    "        class_names (list): List of class names\n",
    "        n_epochs (int): Total number of epochs\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # Get features from the last layer before classification\n",
    "    def hook_fn(module, input, output):\n",
    "        features.append(input[0].cpu().numpy())\n",
    "    \n",
    "    # Register hook to the second-to-last layer\n",
    "    try:\n",
    "        handle = model.fc1.register_forward_hook(hook_fn)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                model(imgs)\n",
    "                labels_list.extend(labels.numpy())\n",
    "        \n",
    "        handle.remove()\n",
    "        \n",
    "        # Concatenate all features\n",
    "        features = np.concatenate(features)\n",
    "        \n",
    "        # Select a subset of data for visualization (max 10000 points)\n",
    "        max_samples = min(10000, len(features))\n",
    "        indices = np.random.choice(len(features), max_samples, replace=False)\n",
    "        \n",
    "        # Log embeddings\n",
    "        writer.add_embedding(\n",
    "            features[indices],\n",
    "            metadata=[class_names[l] for l in np.array(labels_list)[indices]],\n",
    "            label_img=None,\n",
    "            global_step=n_epochs\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to log embeddings to TensorBoard: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08739c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to terminate training when validation loss doesn't improve.\n",
    "    \n",
    "    Args:\n",
    "        patience (int): How many epochs to wait after last improvement.\n",
    "        min_delta (float): Minimum change to qualify as an improvement.\n",
    "        mode (str): 'min' for monitoring metrics that decrease (like loss),\n",
    "                    'max' for metrics that increase (like accuracy).\n",
    "        verbose (bool): If True, prints a message for each improvement.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=10, min_delta=0.0, mode='min', verbose=False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "        # Set the direction based on mode\n",
    "        self.monitor_op = np.less if mode == 'min' else np.greater\n",
    "        self.min_delta = min_delta if mode == 'min' else -min_delta\n",
    "        \n",
    "    def __call__(self, epoch, current_score, model=None, path=None):\n",
    "        \"\"\"Check if training should be stopped.\n",
    "        \n",
    "        Args:\n",
    "            epoch (int): Current epoch number\n",
    "            current_score (float): Current validation metric to monitor\n",
    "            model (torch.nn.Module, optional): Model to save if score improves\n",
    "            path (str, optional): Path to save the model\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if training should stop, False otherwise\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            # First epoch\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.save_checkpoint(current_score, model, path)\n",
    "        elif self.monitor_op(current_score - self.min_delta, self.best_score):\n",
    "            # Score improved\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(current_score, model, path)\n",
    "        else:\n",
    "            # Score did not improve\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                \n",
    "        return self.early_stop\n",
    "    \n",
    "    def save_checkpoint(self, score, model, path):\n",
    "        \"\"\"Save model when validation score improves.\"\"\"\n",
    "        if self.verbose:\n",
    "            improved = 'improved' if self.best_score == score else 'did not improve'\n",
    "            metric_name = 'loss' if self.mode == 'min' else 'score'\n",
    "            print(f'Validation {metric_name} {improved} ({self.best_score:.6f} --> {score:.6f})')\n",
    "        \n",
    "        if model is not None and path is not None:\n",
    "            torch.save(model.state_dict(), path)\n",
    "            if self.verbose:\n",
    "                print(f'Model saved to {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef8ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader, \n",
    "                  epoch_trainer, device, class_names, model_name=\"model\", \n",
    "                  early_stopping_params=None):\n",
    "    \"\"\"Main training loop with TensorBoard logging and early stopping.\n",
    "    \n",
    "    Args:\n",
    "        n_epochs (int): Maximum number of epochs\n",
    "        optimizer: PyTorch optimizer\n",
    "        model: PyTorch model\n",
    "        loss_fn: Loss function\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        device: Device to run on\n",
    "        class_names (list): List of class names\n",
    "        model_name (str): Name for the model in logs\n",
    "        early_stopping_params (dict, optional): Parameters for early stopping\n",
    "            {\n",
    "                'patience': int,\n",
    "                'min_delta': float,\n",
    "                'metric': str ('loss', 'accuracy', or 'f1'),\n",
    "                'mode': str ('min' or 'max')\n",
    "            }\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing best metrics\n",
    "    \"\"\"\n",
    "    print(f\"Training on device {device}\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device=device)\n",
    "    \n",
    "    # Setup early stopping if parameters are provided\n",
    "    early_stopping = None\n",
    "    if early_stopping_params:\n",
    "        metric = early_stopping_params.get('metric', 'f1')\n",
    "        mode = early_stopping_params.get('mode', 'min' if metric == 'loss' else 'max')\n",
    "        patience = early_stopping_params.get('patience', 10)\n",
    "        min_delta = early_stopping_params.get('min_delta', 0.0)\n",
    "        verbose = early_stopping_params.get('verbose', False)\n",
    "        \n",
    "        early_stopping = EarlyStopping(\n",
    "            patience=patience,\n",
    "            min_delta=min_delta,\n",
    "            mode=mode,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        print(f\"Early stopping enabled: monitoring {metric}, mode={mode}, patience={patience}\")\n",
    "    \n",
    "    # Create hyperparameters dict for logging\n",
    "    hyperparams = {\n",
    "        'batch_size': train_loader.batch_size,\n",
    "        'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "        'weight_decay': optimizer.param_groups[0].get('weight_decay', 0),\n",
    "        'epochs': n_epochs,\n",
    "        'optimizer': optimizer.__class__.__name__,\n",
    "        'model_architecture': model.__class__.__name__,\n",
    "    }\n",
    "    \n",
    "    if early_stopping_params:\n",
    "        hyperparams.update({\n",
    "            'early_stopping_metric': early_stopping_params.get('metric', 'loss'),\n",
    "            'early_stopping_patience': early_stopping_params.get('patience', 10),\n",
    "            'early_stopping_min_delta': early_stopping_params.get('min_delta', 0.0),\n",
    "        })\n",
    "    \n",
    "    # Create TensorBoard writer using context manager\n",
    "    with create_summary_writer(model_name, hyperparams) as writer:\n",
    "        best_val_f1 = 0.0\n",
    "        best_metrics = {}\n",
    "        \n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            # Train for one epoch\n",
    "            train_metrics = epoch_trainer(model, train_loader, optimizer, loss_fn, device)\n",
    "            \n",
    "            # Evaluate the model\n",
    "            val_metrics = evaluate_model(model, val_loader, loss_fn, device, class_names)\n",
    "            \n",
    "            # Log metrics to TensorBoard\n",
    "            log_metrics(writer, train_metrics, val_metrics, optimizer, epoch)\n",
    "            \n",
    "            # Log model information periodically\n",
    "            if epoch % 10 == 0 or epoch == 1:\n",
    "                log_model_info(writer, model, epoch, train_loader, device)\n",
    "                log_predictions(writer, model, val_loader, device, class_names, epoch)\n",
    "            \n",
    "            # Print metrics periodically\n",
    "            if epoch == 1 or epoch % 5 == 0:\n",
    "                print(f\"{datetime.datetime.now()} Epoch {epoch}\")\n",
    "                print(f\"  Training:   Loss: {train_metrics['loss']:.4f}, Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "                print(f\"  Validation: Loss: {val_metrics['loss']:.4f}, Accuracy: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1']:.4f}\")\n",
    "            \n",
    "            # Save best model based on F1 score\n",
    "            if val_metrics['f1'] > best_val_f1:\n",
    "                best_val_f1 = val_metrics['f1']\n",
    "                best_metrics = val_metrics.copy()\n",
    "                torch.save(model.state_dict(), f\"runs/{model_name}_best_model.pth\")\n",
    "            \n",
    "            # Check early stopping condition\n",
    "            if early_stopping:\n",
    "                # Get the metric to monitor\n",
    "                metric_name = early_stopping_params.get('metric', 'loss')\n",
    "                current_metric = val_metrics[metric_name]\n",
    "                \n",
    "                # Call early stopping with current metric\n",
    "                model_path = f\"runs/{model_name}_early_stopping.pth\"\n",
    "                if early_stopping(epoch, current_metric, model, model_path):\n",
    "                    print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "                    print(f\"Best {metric_name} was at epoch {early_stopping.best_epoch}\")\n",
    "                    break\n",
    "        \n",
    "        # Log embeddings after training is complete\n",
    "        log_embeddings(writer, model, val_loader, device, class_names, epoch)\n",
    "        \n",
    "        # Log final hyperparameters with metrics\n",
    "        final_metrics = {\n",
    "            'hparam/val_accuracy': val_metrics['accuracy'],\n",
    "            'hparam/val_f1': val_metrics['f1'],\n",
    "            'hparam/val_loss': val_metrics['loss'],\n",
    "            'hparam/epochs_trained': epoch\n",
    "        }\n",
    "        writer.add_hparams(hyperparams, final_metrics)\n",
    "    \n",
    "    # Set the model to evaluation mode after training\n",
    "    model.eval()\n",
    "    print(f\"Training complete. Best validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    # If early stopping was used, report the best epoch\n",
    "    if early_stopping:\n",
    "        print(f\"Best {early_stopping_params.get('metric', 'loss')} was at epoch {early_stopping.best_epoch}\")\n",
    "    \n",
    "    return best_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7312eb",
   "metadata": {},
   "source": [
    "## Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dbd4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=512, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=512, shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463554aa",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f8763e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cifar2_model\"\n",
    "n_epochs = 200\n",
    "early_stopping_params = {\n",
    "    'metric': 'f1',      # Monitor F1 score\n",
    "    'mode': 'max',       # We want to maximize F1\n",
    "    'patience': 5,       # Wait for 5 epochs before stopping\n",
    "    'min_delta': 0.001   # Minimum change to qualify as improvement\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14c6c8",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d5f3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f394b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_Net_20250411-092501\n",
      "2025-04-11 09:25:06.186187 Epoch 1\n",
      "  Training:   Loss: 0.5445, Accuracy: 0.7376\n",
      "  Validation: Loss: 0.4538, Accuracy: 0.7955, F1: 0.7955\n",
      "2025-04-11 09:25:06.754963 Epoch 5\n",
      "  Training:   Loss: 0.3390, Accuracy: 0.8509\n",
      "  Validation: Loss: 0.3317, Accuracy: 0.8505, F1: 0.8505\n",
      "2025-04-11 09:25:07.889733 Epoch 10\n",
      "  Training:   Loss: 0.2932, Accuracy: 0.8755\n",
      "  Validation: Loss: 0.3069, Accuracy: 0.8650, F1: 0.8649\n",
      "2025-04-11 09:25:08.666838 Epoch 15\n",
      "  Training:   Loss: 0.2647, Accuracy: 0.8873\n",
      "  Validation: Loss: 0.2921, Accuracy: 0.8720, F1: 0.8720\n",
      "2025-04-11 09:25:09.870773 Epoch 20\n",
      "  Training:   Loss: 0.2429, Accuracy: 0.8978\n",
      "  Validation: Loss: 0.2858, Accuracy: 0.8785, F1: 0.8785\n",
      "2025-04-11 09:25:10.637587 Epoch 25\n",
      "  Training:   Loss: 0.2227, Accuracy: 0.9078\n",
      "  Validation: Loss: 0.2833, Accuracy: 0.8830, F1: 0.8830\n",
      "Early stopping triggered at epoch 29\n",
      "Best f1 was at epoch 24\n",
      "TensorBoard writer closed for runs/cifar2_model_Net_20250411-092501\n",
      "Training complete. Best validation F1: 0.8850\n",
      "Best f1 was at epoch 24\n"
     ]
    }
   ],
   "source": [
    "# We transfer the model (all its parameters) to the device.\n",
    "model = Net().to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"baseline\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d023541",
   "metadata": {},
   "source": [
    "### Augmenting width or channels in convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a594fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWidth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5383628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetWidth_20250411-092512\n",
      "2025-04-11 09:25:13.141306 Epoch 1\n",
      "  Training:   Loss: 0.4999, Accuracy: 0.7629\n",
      "  Validation: Loss: 0.4134, Accuracy: 0.8140, F1: 0.8138\n",
      "2025-04-11 09:25:13.785222 Epoch 5\n",
      "  Training:   Loss: 0.3268, Accuracy: 0.8617\n",
      "  Validation: Loss: 0.3215, Accuracy: 0.8565, F1: 0.8565\n",
      "2025-04-11 09:25:15.005048 Epoch 10\n",
      "  Training:   Loss: 0.2721, Accuracy: 0.8852\n",
      "  Validation: Loss: 0.2834, Accuracy: 0.8805, F1: 0.8805\n",
      "2025-04-11 09:25:15.833605 Epoch 15\n",
      "  Training:   Loss: 0.2248, Accuracy: 0.9049\n",
      "  Validation: Loss: 0.2769, Accuracy: 0.8915, F1: 0.8914\n",
      "2025-04-11 09:25:17.074308 Epoch 20\n",
      "  Training:   Loss: 0.1900, Accuracy: 0.9217\n",
      "  Validation: Loss: 0.2715, Accuracy: 0.8965, F1: 0.8964\n",
      "2025-04-11 09:25:17.891685 Epoch 25\n",
      "  Training:   Loss: 0.1593, Accuracy: 0.9357\n",
      "  Validation: Loss: 0.2753, Accuracy: 0.8955, F1: 0.8954\n",
      "Early stopping triggered at epoch 25\n",
      "Best f1 was at epoch 20\n",
      "TensorBoard writer closed for runs/cifar2_model_NetWidth_20250411-092512\n",
      "Training complete. Best validation F1: 0.8964\n",
      "Best f1 was at epoch 20\n"
     ]
    }
   ],
   "source": [
    "model = NetWidth(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"width\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61d43c0",
   "metadata": {},
   "source": [
    "### $L_2$-regularizarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96e3e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_epoch_trainer(model, train_loader, optimizer, loss_fn, device):\n",
    "    \"\"\"Run one epoch of training.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        train_loader: Training data loader\n",
    "        optimizer: PyTorch optimizer\n",
    "        loss_fn: Loss function\n",
    "        device: Device to run on\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing training metrics\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_train = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for imgs, labels in train_loader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        l2_lambda = 0.001\n",
    "        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total_train += labels.shape[0]\n",
    "        correct_train += int((predicted == labels).sum())\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_loss = loss_train / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    \n",
    "    return {\n",
    "        'loss': train_loss,\n",
    "        'accuracy': train_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4392a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_Net_20250411-092519\n",
      "2025-04-11 09:25:20.447757 Epoch 1\n",
      "  Training:   Loss: 0.5695, Accuracy: 0.7388\n",
      "  Validation: Loss: 0.4644, Accuracy: 0.7970, F1: 0.7961\n",
      "2025-04-11 09:25:21.217283 Epoch 5\n",
      "  Training:   Loss: 0.3707, Accuracy: 0.8480\n",
      "  Validation: Loss: 0.3395, Accuracy: 0.8495, F1: 0.8495\n",
      "2025-04-11 09:25:22.771159 Epoch 10\n",
      "  Training:   Loss: 0.3290, Accuracy: 0.8694\n",
      "  Validation: Loss: 0.3126, Accuracy: 0.8585, F1: 0.8584\n",
      "2025-04-11 09:25:23.731536 Epoch 15\n",
      "  Training:   Loss: 0.3011, Accuracy: 0.8829\n",
      "  Validation: Loss: 0.2887, Accuracy: 0.8710, F1: 0.8710\n",
      "2025-04-11 09:25:25.091567 Epoch 20\n",
      "  Training:   Loss: 0.2833, Accuracy: 0.8925\n",
      "  Validation: Loss: 0.2825, Accuracy: 0.8770, F1: 0.8768\n",
      "2025-04-11 09:25:26.054980 Epoch 25\n",
      "  Training:   Loss: 0.2663, Accuracy: 0.8997\n",
      "  Validation: Loss: 0.2713, Accuracy: 0.8810, F1: 0.8810\n",
      "2025-04-11 09:25:27.417228 Epoch 30\n",
      "  Training:   Loss: 0.2531, Accuracy: 0.9060\n",
      "  Validation: Loss: 0.2717, Accuracy: 0.8800, F1: 0.8799\n",
      "2025-04-11 09:25:28.377407 Epoch 35\n",
      "  Training:   Loss: 0.2409, Accuracy: 0.9108\n",
      "  Validation: Loss: 0.2660, Accuracy: 0.8855, F1: 0.8855\n",
      "2025-04-11 09:25:29.744761 Epoch 40\n",
      "  Training:   Loss: 0.2311, Accuracy: 0.9164\n",
      "  Validation: Loss: 0.2637, Accuracy: 0.8890, F1: 0.8889\n",
      "Early stopping triggered at epoch 44\n",
      "Best f1 was at epoch 39\n",
      "TensorBoard writer closed for runs/cifar2_model_Net_20250411-092519\n",
      "Training complete. Best validation F1: 0.8904\n",
      "Best f1 was at epoch 39\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"l2 reg\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=l2_epoch_trainer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26c602",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de29f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33e161cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetDropout_20250411-092531\n",
      "2025-04-11 09:25:32.129572 Epoch 1\n",
      "  Training:   Loss: 0.5404, Accuracy: 0.7371\n",
      "  Validation: Loss: 0.4412, Accuracy: 0.7990, F1: 0.7990\n",
      "2025-04-11 09:25:32.824306 Epoch 5\n",
      "  Training:   Loss: 0.3803, Accuracy: 0.8302\n",
      "  Validation: Loss: 0.3457, Accuracy: 0.8440, F1: 0.8440\n",
      "2025-04-11 09:25:34.306563 Epoch 10\n",
      "  Training:   Loss: 0.3373, Accuracy: 0.8528\n",
      "  Validation: Loss: 0.3133, Accuracy: 0.8590, F1: 0.8590\n",
      "2025-04-11 09:25:35.181112 Epoch 15\n",
      "  Training:   Loss: 0.3119, Accuracy: 0.8695\n",
      "  Validation: Loss: 0.2923, Accuracy: 0.8705, F1: 0.8705\n",
      "2025-04-11 09:25:36.461765 Epoch 20\n",
      "  Training:   Loss: 0.2821, Accuracy: 0.8796\n",
      "  Validation: Loss: 0.2759, Accuracy: 0.8810, F1: 0.8810\n",
      "2025-04-11 09:25:37.342106 Epoch 25\n",
      "  Training:   Loss: 0.2567, Accuracy: 0.8928\n",
      "  Validation: Loss: 0.2707, Accuracy: 0.8870, F1: 0.8870\n",
      "2025-04-11 09:25:38.644221 Epoch 30\n",
      "  Training:   Loss: 0.2411, Accuracy: 0.8993\n",
      "  Validation: Loss: 0.2610, Accuracy: 0.8895, F1: 0.8895\n",
      "2025-04-11 09:25:39.483754 Epoch 35\n",
      "  Training:   Loss: 0.2237, Accuracy: 0.9075\n",
      "  Validation: Loss: 0.2542, Accuracy: 0.8995, F1: 0.8995\n",
      "2025-04-11 09:25:40.753232 Epoch 40\n",
      "  Training:   Loss: 0.2184, Accuracy: 0.9094\n",
      "  Validation: Loss: 0.2558, Accuracy: 0.8920, F1: 0.8920\n",
      "Early stopping triggered at epoch 40\n",
      "Best f1 was at epoch 35\n",
      "TensorBoard writer closed for runs/cifar2_model_NetDropout_20250411-092531\n",
      "Training complete. Best validation F1: 0.8995\n",
      "Best f1 was at epoch 35\n"
     ]
    }
   ],
   "source": [
    "model = NetDropout(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"dropout\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9a003",
   "metadata": {},
   "source": [
    "### Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4e234fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_chans1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_chans1 // 2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(out))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1 // 2)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14d9237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetBatchNorm_20250411-092542\n",
      "2025-04-11 09:25:43.761110 Epoch 1\n",
      "  Training:   Loss: 0.4499, Accuracy: 0.7862\n",
      "  Validation: Loss: 0.3632, Accuracy: 0.8395, F1: 0.8395\n",
      "2025-04-11 09:25:44.535547 Epoch 5\n",
      "  Training:   Loss: 0.2838, Accuracy: 0.8792\n",
      "  Validation: Loss: 0.3181, Accuracy: 0.8605, F1: 0.8604\n",
      "2025-04-11 09:25:45.914809 Epoch 10\n",
      "  Training:   Loss: 0.2207, Accuracy: 0.9081\n",
      "  Validation: Loss: 0.2663, Accuracy: 0.8935, F1: 0.8935\n",
      "2025-04-11 09:25:46.888635 Epoch 15\n",
      "  Training:   Loss: 0.1678, Accuracy: 0.9362\n",
      "  Validation: Loss: 0.2763, Accuracy: 0.8950, F1: 0.8950\n",
      "2025-04-11 09:25:48.290251 Epoch 20\n",
      "  Training:   Loss: 0.1243, Accuracy: 0.9570\n",
      "  Validation: Loss: 0.2820, Accuracy: 0.9000, F1: 0.9000\n",
      "2025-04-11 09:25:49.230193 Epoch 25\n",
      "  Training:   Loss: 0.0993, Accuracy: 0.9650\n",
      "  Validation: Loss: 0.3196, Accuracy: 0.8930, F1: 0.8927\n",
      "Early stopping triggered at epoch 25\n",
      "Best f1 was at epoch 20\n",
      "TensorBoard writer closed for runs/cifar2_model_NetBatchNorm_20250411-092542\n",
      "Training complete. Best validation F1: 0.9010\n",
      "Best f1 was at epoch 20\n"
     ]
    }
   ],
   "source": [
    "model = NetBatchNorm(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"batch_norm\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce573c8",
   "metadata": {},
   "source": [
    "### Augmenting depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dd2629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDepth(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)), 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25858d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetDepth_20250411-092551\n",
      "2025-04-11 09:25:51.837536 Epoch 1\n",
      "  Training:   Loss: 0.5904, Accuracy: 0.7185\n",
      "  Validation: Loss: 0.4620, Accuracy: 0.8025, F1: 0.8021\n",
      "2025-04-11 09:25:52.521260 Epoch 5\n",
      "  Training:   Loss: 0.3324, Accuracy: 0.8581\n",
      "  Validation: Loss: 0.3293, Accuracy: 0.8525, F1: 0.8525\n",
      "2025-04-11 09:25:54.011008 Epoch 10\n",
      "  Training:   Loss: 0.2869, Accuracy: 0.8805\n",
      "  Validation: Loss: 0.2885, Accuracy: 0.8765, F1: 0.8765\n",
      "2025-04-11 09:25:54.887371 Epoch 15\n",
      "  Training:   Loss: 0.2539, Accuracy: 0.8954\n",
      "  Validation: Loss: 0.2643, Accuracy: 0.8875, F1: 0.8875\n",
      "2025-04-11 09:25:56.212114 Epoch 20\n",
      "  Training:   Loss: 0.2311, Accuracy: 0.9039\n",
      "  Validation: Loss: 0.2536, Accuracy: 0.8930, F1: 0.8930\n",
      "2025-04-11 09:25:57.093977 Epoch 25\n",
      "  Training:   Loss: 0.2144, Accuracy: 0.9125\n",
      "  Validation: Loss: 0.2497, Accuracy: 0.8975, F1: 0.8975\n",
      "2025-04-11 09:25:58.423263 Epoch 30\n",
      "  Training:   Loss: 0.1964, Accuracy: 0.9185\n",
      "  Validation: Loss: 0.2555, Accuracy: 0.8955, F1: 0.8954\n",
      "2025-04-11 09:25:59.273234 Epoch 35\n",
      "  Training:   Loss: 0.1816, Accuracy: 0.9263\n",
      "  Validation: Loss: 0.2526, Accuracy: 0.8995, F1: 0.8995\n",
      "2025-04-11 09:26:00.586673 Epoch 40\n",
      "  Training:   Loss: 0.1681, Accuracy: 0.9318\n",
      "  Validation: Loss: 0.2614, Accuracy: 0.8995, F1: 0.8994\n",
      "2025-04-11 09:26:01.466265 Epoch 45\n",
      "  Training:   Loss: 0.1599, Accuracy: 0.9362\n",
      "  Validation: Loss: 0.2529, Accuracy: 0.9085, F1: 0.9085\n",
      "2025-04-11 09:26:02.963755 Epoch 50\n",
      "  Training:   Loss: 0.1407, Accuracy: 0.9430\n",
      "  Validation: Loss: 0.2626, Accuracy: 0.9055, F1: 0.9055\n",
      "Early stopping triggered at epoch 51\n",
      "Best f1 was at epoch 46\n",
      "TensorBoard writer closed for runs/cifar2_model_NetDepth_20250411-092551\n",
      "Training complete. Best validation F1: 0.9095\n",
      "Best f1 was at epoch 46\n"
     ]
    }
   ],
   "source": [
    "model = NetDepth(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"depth\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847bbab",
   "metadata": {},
   "source": [
    "### Residual connections (ResNets) or skip connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b723ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_chans1=32):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans1, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_chans1 // 2, n_chans1 // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * n_chans1 // 2, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2)\n",
    "        out = out.view(-1, 4 * 4 * self.n_chans1 // 2)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b20e4acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda\n",
      "Early stopping enabled: monitoring f1, mode=max, patience=5\n",
      "TensorBoard logs will be saved to runs/cifar2_model_NetRes_20250411-092603\n",
      "2025-04-11 09:26:04.369387 Epoch 1\n",
      "  Training:   Loss: 0.5827, Accuracy: 0.7130\n",
      "  Validation: Loss: 0.4473, Accuracy: 0.8140, F1: 0.8139\n",
      "2025-04-11 09:26:05.117676 Epoch 5\n",
      "  Training:   Loss: 0.3327, Accuracy: 0.8583\n",
      "  Validation: Loss: 0.3229, Accuracy: 0.8560, F1: 0.8560\n",
      "2025-04-11 09:26:06.456171 Epoch 10\n",
      "  Training:   Loss: 0.2926, Accuracy: 0.8796\n",
      "  Validation: Loss: 0.2908, Accuracy: 0.8720, F1: 0.8720\n",
      "2025-04-11 09:26:07.354682 Epoch 15\n",
      "  Training:   Loss: 0.2651, Accuracy: 0.8922\n",
      "  Validation: Loss: 0.2749, Accuracy: 0.8800, F1: 0.8800\n",
      "2025-04-11 09:26:08.680805 Epoch 20\n",
      "  Training:   Loss: 0.2408, Accuracy: 0.9003\n",
      "  Validation: Loss: 0.2631, Accuracy: 0.8875, F1: 0.8875\n",
      "2025-04-11 09:26:09.598941 Epoch 25\n",
      "  Training:   Loss: 0.2204, Accuracy: 0.9091\n",
      "  Validation: Loss: 0.2541, Accuracy: 0.8940, F1: 0.8940\n",
      "2025-04-11 09:26:10.942291 Epoch 30\n",
      "  Training:   Loss: 0.2014, Accuracy: 0.9184\n",
      "  Validation: Loss: 0.2476, Accuracy: 0.8990, F1: 0.8990\n",
      "2025-04-11 09:26:11.862183 Epoch 35\n",
      "  Training:   Loss: 0.1831, Accuracy: 0.9268\n",
      "  Validation: Loss: 0.2447, Accuracy: 0.9000, F1: 0.9000\n",
      "2025-04-11 09:26:13.200619 Epoch 40\n",
      "  Training:   Loss: 0.1669, Accuracy: 0.9342\n",
      "  Validation: Loss: 0.2459, Accuracy: 0.9005, F1: 0.9005\n",
      "2025-04-11 09:26:14.115008 Epoch 45\n",
      "  Training:   Loss: 0.1514, Accuracy: 0.9407\n",
      "  Validation: Loss: 0.2506, Accuracy: 0.9025, F1: 0.9024\n",
      "2025-04-11 09:26:15.730139 Epoch 50\n",
      "  Training:   Loss: 0.1412, Accuracy: 0.9450\n",
      "  Validation: Loss: 0.2787, Accuracy: 0.8965, F1: 0.8961\n",
      "Early stopping triggered at epoch 50\n",
      "Best f1 was at epoch 45\n",
      "TensorBoard writer closed for runs/cifar2_model_NetRes_20250411-092603\n",
      "Training complete. Best validation F1: 0.9024\n",
      "Best f1 was at epoch 45\n"
     ]
    }
   ],
   "source": [
    "model = NetRes(n_chans1=32).to(device=device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "all_acc_dict[\"res\"] = training_loop(\n",
    "    n_epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    epoch_trainer=train_epoch,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    class_names=class_names,\n",
    "    model_name=model_name,\n",
    "    early_stopping_params=early_stopping_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b99e923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            n_chans, n_chans, kernel_size=3, padding=1, bias=False\n",
    "        )  # <1>\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity=\"relu\")  # <2>\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d02e5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(*(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede00ff0",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "085c2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation(model_class, model_path, test_loader, device, class_names):\n",
    "    \"\"\"\n",
    "    Perform final evaluation of the model on the test set.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model weights\n",
    "        test_loader: DataLoader for test data\n",
    "        device: Device to run on\n",
    "        class_names: List of class names\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing test metrics\n",
    "    \"\"\"\n",
    "    # Initialize model and load weights\n",
    "    model = model_class().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    test_metrics = evaluate_model(model, test_loader, loss_fn, device, class_names)\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    print(\"\\n===== FINAL MODEL EVALUATION =====\")\n",
    "    print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    y_true = np.array(test_metrics['true_labels'])\n",
    "    y_pred = np.array(test_metrics['predictions'])\n",
    "    \n",
    "    # Precision, recall per class\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)\n",
    "    \n",
    "    print(\"\\nPer-class performance:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"{class_name:10s}: Precision: {precision[i]:.4f}, Recall: {recall[i]:.4f}, F1: {f1[i]:.4f}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    \n",
    "    # Add text annotations to confusion matrix\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d29a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FINAL MODEL EVALUATION =====\n",
      "Test Accuracy: 0.9025\n",
      "Test F1 Score: 0.9024\n",
      "\n",
      "Per-class performance:\n",
      "airplane  : Precision: 0.8808, Recall: 0.9310, F1: 0.9052\n",
      "bird      : Precision: 0.9268, Recall: 0.8740, F1: 0.8996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model_path = \"runs/cifar2_model_best_model.pth\"\n",
    "test_metrics = final_evaluation(NetRes, best_model_path, val_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f5ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
